[{"content":"闲言碎语 前置参考：\nFincasKV - 存储层设计与实现 FincasKV - DB 层设计与实现 本篇对 FincasKV 的网络层实现做一些要点记录。\nRESP Protocol FincasKV 中实现了简单的 RESP 协议，用于兼容 Redis 客户端，实现命令交互。\n我定义了五种常用数据类型：STRING(+), ERROR(-), INTEGER(:), BULK($), ARRAY(*)。每个数据项以 CRLF(\\r\\n) 终止。\n1 2 3 4 5 6 7 8 9 10 11 12 const ( STRING byte = \u0026#39;+\u0026#39; ERROR byte = \u0026#39;-\u0026#39; INTEGER byte = \u0026#39;:\u0026#39; BULK byte = \u0026#39;$\u0026#39; ARRAY byte = \u0026#39;*\u0026#39; ) var ( ErrInvalidRESP = errors.New(\u0026#34;invalid RESP\u0026#34;) CRLF = []byte{\u0026#39;\\r\u0026#39;, \u0026#39;\\n\u0026#39;} ) 对于其他类型直接使用 STRING 类型返回即可。\n首先我们看看解析器部分。在这之前，我们需要先明确 redis-cli 使用RESP协议包装后返回到 server 的命令格式是什么样的。\n看两条例子：\n1 2 redis-cli -p 8911 set a b redis-cli -p 8911 get a set 命令按照 RESP 协议包装后的格式为：\n1 *3\\r\\n$3\\r\\nset\\r\\n$1\\r\\na\\r\\n$1\\r\\nb\\r\\n get 命令按照 RESP 协议包装后的格式为：\n1 *2\\r\\n$3\\r\\nget\\r\\n$1\\r\\na\\r\\n 我们发现这里的返回格式都是以 \u0026lsquo;*\u0026rsquo; 开始，参考我们前面的定义，也就是说每条指令在这里都作为一个数组发送给 server。且整体只需要考虑 ARRAY BULK INTEGER 类型即可。\n我们简单梳理一下 get 命令的解析过程:\n读取 \u0026lsquo;*\u0026rsquo;，确定为数组类型，解析 INTEGER 确定数组长度。 读取 \u0026lsquo;$\u0026rsquo;，确定为 BULK 类型，解析 INTEGER 确定字符串长度。 读取字符串。 重复 2-3 步，直到读取完整个数组。 然后直接看一下 coding 实现，比较简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 type Parser struct { reader *bufio.Reader } func (p *Parser) Parse() (*Command, error) { typ, err := p.reader.ReadByte() if err != nil { ... } switch typ { case ARRAY: return p.parseArray() default: return nil, ErrInvalidRESP } } func (p *Parser) parseArray() (*Command, error) { length, err := p.parseInteger() if err != nil { ... } if length \u0026lt; 1 { ... } command := \u0026amp;Command{ Args: make([][]byte, length), } for i := 0; i \u0026lt; length; i++ { typ, err := p.reader.ReadByte() if err != nil { ... } if typ != BULK { ... } bulk, err := p.parseBulkString() if err != nil { ... } command.Args[i] = bulk } command.Name = string(command.Args[0]) command.Args = command.Args[1:] return command, nil } func (p *Parser) parseBulkString() ([]byte, error) { length, err := p.parseInteger() if err != nil { ... } if length \u0026lt; 0 { ... } bulk := make([]byte, length) if _, err := io.ReadFull(p.reader, bulk); err != nil { ... } crlf := make([]byte, 2) if _, err := io.ReadFull(p.reader, crlf); err != nil { ... } if !bytes.Equal(crlf, CRLF) { ... } return bulk, nil } func (p *Parser) parseInteger() (int, error) { line, err := p.reader.ReadString(\u0026#39;\\n\u0026#39;) if err != nil { ... } if len(line) \u0026lt; 3 || line[len(line)-2] != \u0026#39;\\r\u0026#39; { ... } n, err := strconv.Atoi(line[:len(line)-2]) if err != nil { ... } return n, nil } 然后看看写入器部分，用于将结果包装成 RESP 协议后写入到客户端，还是先看一下基本的格式（以 STRING 举例）：\n假设我执行了 set a b 需要返回 OK，那么按照 RESP 协议包装后的格式为：+OK\\r\\n。\n现在我们可以很容易的写出以下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func (w *Writer) WriteString(s string) error { _, err := w.writer.Write([]byte{STRING}) if err != nil { return err } _, err = w.writer.Write([]byte(s)) if err != nil { return err } _, err = w.writer.Write(CRLF) return err } ERROR 和 INTEGER 同理。对于 BULK 类型略有不同，我们需要先写入长度，然后写入字符串，最后写入 CRLF。而数组则是先写入长度，然后写入CRLF，之后追加若干个 BULK。这里不做展开。\nNetwork 首先我们从整体出发看看 FincasKV 的网络层的结构。\n连接建立: 客户端（Client）向服务器（Server）发起连接请求。 服务器接收连接并将其传递给事件循环（EventLoop）进行处理。 创建连接处理器: 事件循环为每个连接创建一个连接处理器（ConnHandler），负责管理与客户端的交互。 命令处理循环: 在命令处理的循环中，客户端向连接处理器发送命令。 连接处理器将命令传递给协议解析器（Parser）进行解析。 解析命令: 协议解析器解析命令并将其传递给命令处理器（Handler）进行处理。 判断命令类型: 写命令处理: 如果是写命令且系统处于集群模式，命令处理器将检查当前节点是否为领导者（Leader）。 如果是领导者，命令被应用到 DB 层（FincasDB）。 如果是跟随者（Follower），则连接处理器会将请求重定向到领导者节点。 读命令处理: 如果是读命令或单节点模式，则直接在数据库中执行命令。 返回响应: 命令处理器将结果返回给连接处理器。 连接处理器将响应发送回客户端。 同时可以参考以下时序图：\n下面看一下 Connection 的代码摘要：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 type Connection struct { conn netpoll.Connection parser *protocol.Parser writer *protocol.Writer ctx context.Context cancel context.CancelFunc closed bool mu sync.RWMutex } func New(conn netpoll.Connection) *Connection { ctx, cancel := context.WithCancel(context.Background()) c := \u0026amp;Connection{ conn: conn, parser: protocol.NewParser(conn), writer: protocol.NewWriter(conn), ctx: ctx, cancel: cancel, } return c } func (c *Connection) Close() error { c.mu.Lock() defer c.mu.Unlock() if c.closed { return nil } c.closed = true c.cancel() return c.conn.Close() } func (c *Connection) IsClosed() bool { c.mu.RLock() defer c.mu.RUnlock() return c.closed } func (c *Connection) ReadCommand() (*protocol.Command, error) { c.mu.Lock() defer c.mu.Unlock() cmd, err := c.parser.Parse() if err != nil { return nil, err } return cmd, nil } func (c *Connection) WriteString(s string) error { c.mu.Lock() defer c.mu.Unlock() err := c.writer.WriteString(s) if err != nil { return err } return nil } // 以下方法同理 func (c *Connection) WriteError(err error) error { ... } func (c *Connection) WriteInteger(n int64) error { ... } func (c *Connection) WriteBulk(b []byte) error { ... } func (c *Connection) WriteArray(arr [][]byte) error { ... } Server:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 type Config struct { Addr string IdleTimeout time.Duration MaxConnections int ReadTimeout time.Duration WriteTimeout time.Duration } type Server struct { cfg *Config db *database.FincasDB handler *handler.Handler eventLoop netpoll.EventLoop conns sync.Map connWg sync.WaitGroup stats *Stats ctx context.Context cancel context.CancelFunc closed bool closeMu sync.RWMutex metricsTicker *time.Ticker metricsCancel context.CancelFunc node *node.Node } func New(db *database.FincasDB, address *string) (*Server, error) { var ( addr = \u0026#34;:8911\u0026#34; idleTimeout = 5 * time.Second maxConnections = 1000 readTimeout = 10 * time.Second writeTimeout = 10 * time.Second ) // 省略配置获取部分 cfg := \u0026amp;Config{ Addr: addr, IdleTimeout: idleTimeout, MaxConnections: maxConnections, ReadTimeout: readTimeout, WriteTimeout: writeTimeout, } ctx, cancel := context.WithCancel(context.Background()) s := \u0026amp;Server{ cfg: cfg, db: db, handler: handler.New(db), stats: \u0026amp;Stats{StartTime: time.Now()}, ctx: ctx, cancel: cancel, } eventLoop, err := netpoll.NewEventLoop( func(ctx context.Context, conn netpoll.Connection) error { return s.handleConnection(ctx, conn) }, netpoll.WithOnPrepare(func(connection netpoll.Connection) context.Context { return context.Background() }), netpoll.WithIdleTimeout(idleTimeout), netpoll.WithReadTimeout(readTimeout), netpoll.WithWriteTimeout(writeTimeout), ) if err != nil { return nil, fmt.Errorf(\u0026#34;failed to create netpoll eventLoop: %v\u0026#34;, err) } s.eventLoop = eventLoop return s, nil } func (s *Server) Start() error { s.closeMu.Lock() if s.closed { s.closeMu.Unlock() return fmt.Errorf(\u0026#34;server is already closed\u0026#34;) } s.closeMu.Unlock() s.startMetricsCollection() listener, err := netpoll.CreateListener(\u0026#34;tcp\u0026#34;, s.cfg.Addr) if err != nil { return fmt.Errorf(\u0026#34;failed to create listener: %v\u0026#34;, err) } log.Printf(\u0026#34;listening on %s\u0026#34;, s.cfg.Addr) if err := s.eventLoop.Serve(listener); err != nil { return fmt.Errorf(\u0026#34;failed to start eventLoop: %v\u0026#34;, err) } return nil } func (s *Server) Stop() error { s.closeMu.Lock() if s.closed { s.closeMu.Unlock() return fmt.Errorf(\u0026#34;server already closed\u0026#34;) } s.closed = true s.closeMu.Unlock() s.cancel() if s.metricsCancel != nil { s.metricsCancel() } if s.node != nil { if err := s.node.Shutdown(); err != nil { log.Printf(\u0026#34;failed to shutdown node: %v\u0026#34;, err) } } s.conns.Range(func(key, value interface{}) bool { if c, ok := value.(conn.Connection); ok { c.Close() } return true }) s.connWg.Wait() return s.eventLoop.Shutdown(context.Background()) } func (s *Server) handleConnection(ctx context.Context, c netpoll.Connection) error { if atomic.LoadInt64(\u0026amp;s.stats.ConnCount) \u0026gt;= int64(s.cfg.MaxConnections) { c.Close() return fmt.Errorf(\u0026#34;max connections reached\u0026#34;) } connection := conn.New(c) s.conns.Store(c, connection) s.connWg.Add(1) defer func() { connection.Close() s.conns.Delete(c) s.connWg.Done() }() for { select { case \u0026lt;-ctx.Done(): return nil default: start := time.Now() cmd, err := connection.ReadCommand() if err != nil { if errors.Is(err, netpoll.ErrConnClosed) { return nil } log.Printf(\u0026#34;failed to read command: %v\u0026#34;, err) continue } // 处理 cluster 命令 if strings.ToUpper(cmd.Name) == \u0026#34;CLUSTER\u0026#34; { if err := s.handleClusterCommand(connection, cmd); err != nil { log.Printf(\u0026#34;failed to handle cluster command: %v\u0026#34;, err) } continue } // 禁止非Leader节点处理写操作 cmdP, ok := isWriteCommand(cmd.Name) if ok \u0026amp;\u0026amp; s.node != nil \u0026amp;\u0026amp; !s.node.IsLeader() { leaderAddr := s.node return connection.WriteError(fmt.Errorf(\u0026#34;redirect to leader: %s\u0026#34;, leaderAddr)) } if err := s.handler.Handle(connection, cmd); err != nil { s.stats.IncrErrorCount() log.Printf(\u0026#34;failed to handle command: %v\u0026#34;, err) } else if s.node != nil { err := s.node.Apply(command.New(cmdP.CmdType, cmdP.Method, cmd.Args)) if err != nil { return fmt.Errorf(\u0026#34;failed to apply command: %v\u0026#34;, err) } } } } } func (s *Server) initCluster(conf *node.Config) error { n, err := node.New(s.db, conf) if err != nil { ... } s.node = n return nil } // 以下方法用于判断是否为写命令以及和 Cluster Handler 相对应 type cmdPair struct { CmdType command.CmdTyp Method command.MethodTyp } func isWriteCommand(cmd string) (cmdPair, bool) { wCmds := map[string]cmdPair{ \u0026#34;SET\u0026#34;: {command.CmdString, command.MethodSet}, \u0026#34;DEL\u0026#34;: {command.CmdString, command.MethodDel}, \u0026#34;INCR\u0026#34;: {command.CmdString, command.MethodIncr}, \u0026#34;INCRBY\u0026#34;: {command.CmdString, command.MethodIncrBy}, \u0026#34;DECR\u0026#34;: {command.CmdString, command.MethodDecr}, \u0026#34;DECRBY\u0026#34;: {command.CmdString, command.MethodDecrBy}, \u0026#34;APPEND\u0026#34;: {command.CmdString, command.MethodAppend}, \u0026#34;GETSET\u0026#34;: {command.CmdString, command.MethodGetSet}, \u0026#34;SETNX\u0026#34;: {command.CmdString, command.MethodSetNX}, \u0026#34;MSET\u0026#34;: {command.CmdString, command.MethodMSet}, \u0026#34;HSET\u0026#34;: {command.CmdHash, command.MethodHSet}, \u0026#34;HMSET\u0026#34;: {command.CmdHash, command.MethodHMSet}, \u0026#34;HDEL\u0026#34;: {command.CmdHash, command.MethodHDel}, \u0026#34;HINCRBY\u0026#34;: {command.CmdHash, command.MethodHIncrBy}, \u0026#34;HINCRBYFLOAT\u0026#34;: {command.CmdHash, command.MethodHIncrByFloat}, \u0026#34;HSETNX\u0026#34;: {command.CmdHash, command.MethodHSetNX}, \u0026#34;LPUSH\u0026#34;: {command.CmdList, command.MethodLPush}, \u0026#34;RPUSH\u0026#34;: {command.CmdList, command.MethodRPush}, \u0026#34;LPOP\u0026#34;: {command.CmdList, command.MethodLPop}, \u0026#34;RPOP\u0026#34;: {command.CmdList, command.MethodRPop}, \u0026#34;LTRIM\u0026#34;: {command.CmdList, command.MethodLTrim}, \u0026#34;LINSERT\u0026#34;: {command.CmdList, command.MethodLInsert}, \u0026#34;SADD\u0026#34;: {command.CmdSet, command.MethodSAdd}, \u0026#34;SREM\u0026#34;: {command.CmdSet, command.MethodSRem}, \u0026#34;SPOP\u0026#34;: {command.CmdSet, command.MethodSPop}, \u0026#34;SMOVE\u0026#34;: {command.CmdSet, command.MethodSMove}, \u0026#34;ZADD\u0026#34;: {command.CmdZSet, command.MethodZAdd}, \u0026#34;ZREM\u0026#34;: {command.CmdZSet, command.MethodZRem}, \u0026#34;ZINCRBY\u0026#34;: {command.CmdZSet, command.MethodZIncrBy}, \u0026#34;ZREMRANGEBYRANK\u0026#34;: {command.CmdZSet, command.MethodZRemRangeByRank}, \u0026#34;ZREMRANGEBYSCORE\u0026#34;: {command.CmdZSet, command.MethodZRemRangeByScore}, } val, ok := wCmds[strings.ToUpper(cmd)] return val, ok } Handler 简要代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 type Handler struct { db *database.FincasDB } func New(db *database.FincasDB) *Handler { return \u0026amp;Handler{ db: db, } } func (h *Handler) Handle(conn *conn.Connection, cmd *protocol.Command) error { switch strings.ToUpper(cmd.Name) { case \u0026#34;PING\u0026#34;: return h.handlePing(conn, cmd) // 省略其他指令 default: return conn.WriteError(errors.New(\u0026#34;unknown command\u0026#34;)) } } func (h *Handler) handlePing(conn *conn.Connection, cmd *protocol.Command) error { if len(cmd.Args) \u0026gt; 1 { return conn.WriteError(ErrWrongArgCount) } if len(cmd.Args) == 1 { return conn.WriteString(fmt.Sprintf(\u0026#34;PONG %s\u0026#34;, string(cmd.Args[0]))) } return conn.WriteString(\u0026#34;PONG\u0026#34;) } // 省略其他指令 handle 对于分布式支持更多的是基于 hashicorp/raft 库对于网络层的扩展，且 FSM 部分和 Handler 有些重复，这里可以直接阅读 Raft 论文后直接看 cluster 包下的代码即可。后续会对 FSM 进行一些调整，复用 Network Handler。\n结束。\n","date":"2025-02-15T15:27:55+08:00","permalink":"https://finntew.github.io/p/fincas-kv-network-design-and-impl/","title":"FincasKV - 网络层设计与实现"},{"content":"闲言碎语 前置参考：\nFincasKV - 存储层设计与实现 本篇继续对 FincasKV 的 DB 层实现做一些记录。\nPut With TTL 这里实现 TTL 操作之前有想到两个实现方案：\n对存储层进行一些修改，在原本 DataFile 的基础上，对于每个 Record 新增一个 expireAt 字段。 在进行 TTL 相关操作时新增 TTL 元信息文件，按照 {key, expireAt} 的方式存储。 最终使用了第二种方案，将 TTL 操作解耦出来完全放在 DB 层实现，降低一些维护成本，同时更加方便清理过期数据。\n然后考虑怎么处理过期的 key，同样的想到这里有两种方案：\n定时扫描，定期扫描所有 key，删除过期的 key。 惰性删除，在查询某个 key 时，如果设置了 TTL，且已经过期，则删除该 key。 这里使用惰性删除的方式，避免定时扫描全量数据造成的性能问题。不过缺点也比较明显，如果设置了 TTL 的 key 一直没有被访问，那么该 key 就会一直存在于内存中，造成内存浪费。\n在之后了解到 redis 中一个优秀的实现：结合定时扫描和惰性删除的方式，使用了一种混合的方式：\n定时扫描每次只抽出一部分 key 进行检查。避免全量扫描时间过长。 对于没有扫描到的 key 进行惰性删除。 这样可以均衡两种方式的优缺点，后续可能考虑使用这种方式优化一下这部分的实现。\n一些代码摘要：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 type DB struct { // ... expireMap map[string]time.Time expireMu sync.RWMutex // ... ttlPath string needFlush bool // ... } func (db *DB) Get(key string) (string, error) { if db.isExpired(key) { _ = db.deleteExpiredKey(key) return \u0026#34;\u0026#34;, err_def.ErrKeyNotFound } // ... } func (db *DB) Expire(key string, ttl time.Duration) error { if ttl \u0026lt;= 0 { ... } ex, err := db.Exists(key) if err != nil { return err } if !ex { return err_def.ErrKeyNotFound } expireAt := time.Now().Add(ttl) db.expireMu.Lock() db.expireMap[key] = expireAt db.needFlush = db.needFlush || db.dbOpts.FlushTTLOnChange db.expireMu.Unlock() if db.dbOpts.FlushTTLOnChange { _ = db.saveTTLMetadata() } return nil } func (db *DB) Persist(key string) error { ex, err := db.Exists(key) if err != nil { ... } if !ex { return err_def.ErrKeyNotFound } db.expireMu.Lock() delete(db.expireMap, key) db.needFlush = db.needFlush || db.dbOpts.FlushTTLOnChange db.expireMu.Unlock() if db.dbOpts.FlushTTLOnChange { _ = db.saveTTLMetadata() } return nil } func (db *DB) isExpired(key string) bool { db.expireMu.RLock() expAt, ok := db.expireMap[key] db.expireMu.RUnlock() return ok \u0026amp;\u0026amp; time.Now().After(expAt) } func (db *DB) deleteExpiredKey(key string) error { err := db.bc.Del(key) db.expireMu.Lock() delete(db.expireMap, key) db.needFlush = db.needFlush || db.dbOpts.FlushTTLOnChange db.expireMu.Unlock() if db.dbOpts.FlushTTLOnChange { _ = db.saveTTLMetadata() } return err } Write Batch 在整个项目完结后来看，Batch 操作实际还是应该在存储层实现的。\n因为 Batch 最大的好处应该是去减少 IO 次数，降低磁盘 IO 压力。但是在 DB 层实现的话，目前可以看到的收益大概只有减少锁资源的使用。\n之后会对这部分进行一些优化。\n这里感觉比较好理解，可以直接看一下代码摘要：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 type operation struct { typ OpType key string value string ttl time.Duration created time.Time priority int // 操作优先级 } type WriteBatch struct { // ... operations []operation mu sync.Mutex committed bool // ... } // 省略 Put/Delete等方法 func (wb *WriteBatch) Commit() error { ctx, cancel := context.WithTimeout(context.Background(), wb.opts.CommitTimeout) defer cancel() return wb.CommitWithContext(ctx) } func (wb *WriteBatch) CommitWithContext(ctx context.Context) error { wb.mu.Lock() defer wb.mu.Unlock() if wb.committed { ... } if len(wb.operations) == 0 { wb.committed = true return nil } // 操作排序和合并 wb.optimizeOperations() // 批量写入准备，过滤非法操作 if err := wb.prepareBatch(); err != nil { return err } // 异步处理 if wb.opts.AsyncCommit { go wb.executeOperations(ctx) return nil } return wb.executeOperations(ctx) } func (wb *WriteBatch) optimizeOperations() { // 按优先级排序 sort.Slice(wb.operations, func(i, j int) bool { return wb.operations[i].priority \u0026gt; wb.operations[j].priority }) // 合并相同key的操作 optimized := make([]operation, 0, len(wb.operations)) keyOps := make(map[string]operation) for _, op := range wb.operations { existing, exists := keyOps[op.key] if !exists { keyOps[op.key] = op continue } // 合并操作 // 下面两种组合不需要合并 if existing.typ == OpPut \u0026amp;\u0026amp; op.typ == OpExpire { continue } if existing.typ == OpExpire \u0026amp;\u0026amp; op.typ == OpPersist { continue } merged := wb.mergeOperations(existing, op) keyOps[op.key] = merged } // 构建操作列表 for _, op := range keyOps { optimized = append(optimized, op) } wb.operations = optimized } func (wb *WriteBatch) mergeOperations(op1, op2 operation) operation { // 只需要保留最后一次操作 if op2.created.After(op1.created) { return op2 } return op1 } func (wb *WriteBatch) prepareBatch() error { keysMap := make(map[string]struct{}) for _, op := range wb.operations { keysMap[op.key] = struct{}{} } for _, op := range wb.operations { switch op.typ { case OpPut: continue case OpDelete, OpExpire, OpPersist: exists, err := wb.db.Exists(op.key) if err != nil { ... } if _, ok := keysMap[op.key]; !exists \u0026amp;\u0026amp; !ok { ... } } } return nil } func (wb *WriteBatch) executeOperations(ctx context.Context) error { wb.db.expireMu.Lock() defer wb.db.expireMu.Unlock() if err := ctx.Err(); err != nil { ... } for _, op := range wb.operations { select { case \u0026lt;-ctx.Done(): wb.rollback(op) return ctx.Err() default: if err := wb.executeOperation(op); err != nil { wb.rollback(op) return err } } } if wb.db.needFlush \u0026amp;\u0026amp; wb.db.dbOpts.FlushTTLOnChange { if err := wb.db.saveTTLMetadata(); err != nil { ... } wb.db.needFlush = false } wb.committed = true return nil } func (wb *WriteBatch) executeOperation(op operation) error { var err error switch op.typ { case OpPut: err = wb.db.bc.Put(op.key, []byte(op.value)) case OpDelete: err = wb.db.bc.Del(op.key) if err == nil { delete(wb.db.expireMap, op.key) } case OpExpire: expireAt := op.created.Add(op.ttl) wb.db.expireMap[op.key] = expireAt wb.db.needFlush = true case OpPersist: delete(wb.db.expireMap, op.key) wb.db.needFlush = true } return err } func (wb *WriteBatch) rollback(failedOp operation) { // 倒序遍历已执行的操作回滚 for i := len(wb.operations) - 1; i \u0026gt;= 0; i-- { op := wb.operations[i] if op == failedOp { break } switch op.typ { case OpPut: // 删除已写入的数据 _ = wb.db.bc.Del(op.key) case OpDelete: // 恢复删除的数据 if val, err := wb.db.Get(op.key); err == nil { _ = wb.db.bc.Put(op.key, []byte(val)) } case OpExpire: // 取消过期 delete(wb.db.expireMap, op.key) case OpPersist: // 恢复过期 if expAt, ok := wb.db.expireMap[op.key]; ok { wb.db.expireMap[op.key] = expAt } } } } 可以使用 sync.Pool 优化一下 WriteBatch 的创建和释放，这里就不展开了。\n其中省略了一些错误日志之类的部分。\nRedis DataStructure 这里记录一下 Redis 中的一些常见数据结构在 FincasKV 中的设计。（只对数据格式做一些记录，详细实现可以参考仓库中的具体代码）\n我们首先可以想到一种最直观最好实现的方式，即使用序列化的方式组织 value，比如 JSON。\n但是不难想到这么做有一些非常明显的弊端：\n序列化的方式会导致一些对内容无意义的格式字符额外占用空间。 我们在每次读写时都需要进行序列化 or 反序列化操作，会有一定的额外性能开销。 所以这里采用另一种实现方式：多 Key，也就是在 FincasKV 中，每个 Redis 数据结构的对象会由多个小 Key 构成，而非一个整体的大 Key。\n下面是对于不同数据结构的具体设计。\nString String 的实现比较简单，我们按照 string:{key} -\u0026gt; {value} 的格式组织即可。\nHash 对于 Hash，我们发现它需要额外维护一个长度元信息，所以我们可以将 Hash 拆分为两个部分：\n一个长度键值对：hash:{key}:__len__ -\u0026gt; {len} 若干个字段键值对：hash:{key}:{field} -\u0026gt; {value} List 我们可以将 List 类比到一个链表结构，不难想到我们需要维护以下元信息：\n一个长度键值对：list:{key}:__len__ -\u0026gt; {len} 一个头指针键值对：list:{key}:__head__ -\u0026gt; {head} 一个尾指针键值对：list:{key}:__tail__ -\u0026gt; {tail} 以及若干个节点键值对：list:{key}:{index} -\u0026gt; {value}。\nSet Set 和 Hash 类似，区别在与 member 并非键值对形式，按照以下格式组织：\n一个长度键值对：set:{key}:__len__ -\u0026gt; {len} 若干个成员键值对：set:{key}:{member} -\u0026gt; \u0026quot;\u0026quot; ZSet 对于 ZSet，它是一个有序集合，且 member 需要满足 member -\u0026gt; score，我们将数据存储和排序拆分为两个部分考虑：\n数据键值对：zset:{key}:{member} -\u0026gt; {score} 排序键值对：zset:{key}:s:{score}:{member} -\u0026gt; {member} 注意：这里 score 直接使用 float 显然对于排序是无意义的，我们需要进行以下处理：\n1 2 3 4 5 6 7 8 9 func float64ToOrderedString(score float64) string { bits := math.Float64bits(score) if (bits \u0026amp; (1 \u0026lt;\u0026lt; 63)) != 0 { bits = ^bits } else { bits = bits | (1 \u0026lt;\u0026lt; 63) } return fmt.Sprintf(\u0026#34;%016x\u0026#34;, bits) } 一些可优化的点 目前想到的只有 ZSet 部分的优化。\n现在 ZSet 实现是很暴力的直接排序进行的，这里可以使用 SkipList 进行优化，大概记录如下：\n首次读取 or 修改已有键/写入新键时构造 SkipList。 后续写入使用类似 WAL 的方式（Bitcask 本身就是类 WAL 的），所以写入流程为：先写入 Bitcask，然后向 SkipList 中插入。 读取时因为已经构造好了 SkipList，所以直接读取 SkipList 即可。 结束。\n","date":"2025-02-14T18:00:02+08:00","permalink":"https://finntew.github.io/p/fincas-kv-db-design-and-impl/","title":"FincasKV - DB层设计与实现"},{"content":"闲言碎语 在去年写我的第一版简历的时候做过一个项目 FinnKV，一个基于 Bitcask 存储模型实现的 KV 存储，当时做的比较简陋，不出意外的，在投递过程中反馈也比较差，于是趁着这个寒假的时间重构了一下项目，引入了一些新的内容，在此做一些记录。\n重构后的项目命名为 FincasKV，一个基于 Bitcask 存储模型的分布式 KV 存储。\n仓库地址：FincasKV\nBitcask Bitcask 是一种高效的键值存储模型，采用类 LSM 结构。本质上 Bitcask 就是一个具有固定结构、支持内存索引，Append Only 的日志文件目录。通过内存索引中保存的键到Offset的映射相关的信息，实现高效查找。\n数据文件(DataFile) 如上所述，每个 DataFile 都是一个 Append Only 的日志文件，用于保存键值对极其相关的元信息，其中每条日志(Record)呈如下结构：\n1 2 3 4 5 6 7 8 9 10 11 type KVItem struct { Key []byte Value []byte } type Record struct { Timestamp int64 Checksum uint64 Flags uint32 KVItem } 实际写入时还应该存储 CRC 校验和，用于校验数据的完整性。不难想到 CRC 是在 Record 构建完整后进行写入操作时计算，以及在读出时确认位置后读取 KV 前校验，所以 Record 中并不需要添加 CRC 字段。\n一个 Bitcask 实例包含多个 DataFile，但只有一个为 Active DataFile，且仅有 Active DataFile 可变，允许追加写入操作，其与的 Old DataFile 不可变，只允许读操作。\n在当前 Active DataFile 的大小到达阈值的时候，我们需要将其关闭，并创建新的日志文件作为 Active DataFile。\n还有一种会轮转 Active DataFile 的情况，在 Bitcask 中，我们认为，只要日志文件被关闭了，无论是否主动关闭，我们都将其视为 Old DataFile，永远不再 Reopen 允许写入操作。\n内存索引 前面提到过 Bitcask 内存索引存储了键到 Offset 的映射信息，用于快速查找。每条索引称为一个 Entry，结构如下：\n1 2 3 4 5 6 type Entry struct { FileID int Offset int64 Size uint32 Timestamp int64 } Put, Get, Del Bitcask 中所有的写操作都以追加日志的方式进行，但是显然新增/修改和删除操作实际上并不相同，所以我们需要一种区分二者的方式。论文中提到对于删除操作使用墓碑机制。\n注意到 Record 中已经有 Flag 字段，我们还需定义如下两种状态标记：\n1 2 3 4 const ( FlagNormal uint32 = iota // 表示新增或者修改操作，这里二者并不需要区分，读取时取最近一条即可 FlagDeleted // 表示删除操作 ) 处理完以上问题后，Put 和 Del 的逻辑就显而易见了：\nPut：构建 Record，设置 Flag 为 FlagNormal，追加写入 Active DataFile，新增/更新对应键的内存索引。 Del：构建 Record，设置 Flag 为 FlagDeleted，追加写入 Active DataFile，删除对应键的内存索引。 而对于 Get，我们参考 Entry 结构，不难发现流程如下：\n通过键获取对应的 Entry。 通过 Entry 中的 FileID 确定目标 DataFile。 假设整个文件为 data[:]，那么我们只需要读出 data[Entry.Offset:Entry.Offset + Entry.Size] 即为需要的 Record。 不难算出 HeaderSize = timestamp(8) + flags(4) + keyLen(4) + valueLen(4) = 20 bytes，而 CRC 校验和为 8 bytes，所以 Record 实际大小为 28 bytes + len(Key) + len(Value)。 DataFile 中每条 Record 按照 \u0026ldquo;Header | Key | Value | CRC\u0026rdquo; 这样存储，所以我们读出 data[Entry.Offset + HeaderSize:Entry.Offset + Entry.Size - 8] 即为 \u0026ldquo;Key | Value\u0026rdquo;。 Merge 到这里，Merge 操作就很容易了，论文指出 Merge 即为遍历所有有效键值对，将其写入到新的 DataFile 中，全部完成后删除原本的 DataFile。\n有效键值对在这里即为当前内存缓存中的键对应的键值对，此时 Merge 的流程已经很清晰了：\n创建 MergeDir，在其中创建新的 Active DataFile。 遍历内存索引的键，依次 Get，并构建新的 Record 写入 MergeDir 中的 Active DataFile。 全部完成后，删除 DataDir，将 MergeDir 重命名作为新的 DataDir。 至此，基本的 Bitcask 模型已经实现了，下面我们考虑一些优化。\nFileManager - AsyncWrite Bitcask 是一个依赖文件系统的存储模型，那我们首先可以想到，对写入操作进行优化，也就是这里提到的异步写。\n在此之前我先对现有的代码结构进行了一些调整，注意到对于文件的操作可以解耦，所以我将 rotate, Write, Read, Sync 以及 Encode/Decode 这些操作解耦出来，实现了一个 FileManager，方便之后优化改进。\n然后是异步写的实现，我们知道，Golang 的并发原语是非常强大的，我们可以依据此很轻松的将写入操作进行异步化。\n首先定义对应的结构：\n1 2 3 4 5 6 7 8 9 type AsyncWriteReq struct { DataByte []byte Resp chan AsyncWriteResp } type AsyncWriteResp struct { Entry storage2.Entry Err error } 然后是实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 func (fm *FileManager) WriteAsync(r *storage2.Record) \u0026lt;-chan AsyncWriteResp { result := make(chan AsyncWriteResp, 1) // 编码成二进制 data, err := encodeRecord(r) if err != nil { // 如果编码失败，直接返回错误 go func() { result \u0026lt;- AsyncWriteResp{Err: err} close(result) }() return result } req := AsyncWriteReq{ DataByte: data, Resp: make(chan AsyncWriteResp, 1), } select { case fm.writeChan \u0026lt;- req: // 异步读出写结果再转发 go func() { res := \u0026lt;-req.Resp result \u0026lt;- res close(result) }() case \u0026lt;-fm.stopChan: // 如果已经关闭，则立即返回错误 go func() { result \u0026lt;- AsyncWriteResp{Err: err_def.ErrDBClosed} close(result) }() } return result } // processWrites 消费 fm.writeChan，执行实际写入 func (fm *FileManager) processWrites() { defer fm.wg.Done() for { select { case req, ok := \u0026lt;-fm.writeChan: if !ok { return } entry, err := fm.syncWrite(req.DataByte) req.Resp \u0026lt;- AsyncWriteResp{Entry: entry, Err: err} close(req.Resp) case \u0026lt;-fm.stopChan: return } } } // syncWrite 内部真正执行写入的函数 func (fm *FileManager) syncWrite(data []byte) (storage2.Entry, error) { for { current := fm.GetActiveFile() if current == nil { ... } if current.Closed.Load() { // 已关闭，进行轮转 _, err := fm.rotateFile() if err != nil { ... } continue } // 检查剩余空间，如果不够则轮转 offsetNow := current.Offset.Load() if offsetNow+int64(len(data)) \u0026gt; fm.maxFileSize { _, err := fm.rotateFile() if err != nil { ... } continue } // 计算写入起始位置 newOffset := current.Offset.Add(int64(len(data))) writePos := newOffset - int64(len(data)) // 执行写入 n, err := current.File.WriteAt(data, writePos) if err != nil || n != len(data) { // 写失败，则关闭当前文件并轮转 _ = current.File.Close() current.Closed.Store(true) _, rotateErr := fm.rotateFile() if rotateErr != nil { ... } return storage2.Entry{}, err_def.ErrWriteFailed } // 写成功，返回对应的索引信息 return storage2.Entry{ ... }, nil } } 如上，我们通过 writeChan 进行异步写，然后在 processWrites 中消费 writeChan，将实际写操作异步延迟到 syncWrite 中执行。\n在写入 writeChan 成功时直接返回结果，避免了阻塞等待，有效提高效率。\nMulti-Type Shard MemIndex 首先规定我们所有的内存索引数据结构需要满足以下接口定义：\n1 2 3 4 5 6 7 type MemIndex[KeyType comparable, ValueType any] interface { Put(key KeyType, value ValueType) error Get(key KeyType) (ValueType, error) Del(key KeyType) error Foreach(f func(key KeyType, value ValueType) bool) error Clear() error } 目前为存储层也就是 Bitcask 实现了多类型的内存索引，包括：\nBTree: 适合大数据集，需要键排序的场景。 SkipList: 适合数据量适中，且数据频繁变化的场景。 SwissTable: 适合高并发场景，以及内存限制严苛且需要高效查找的场景。 可以通过配置文件自由的配置使用哪种内存索引数据结构，以及相关的对应参数。\n然后我们进一步进行优化，即实现 Shard MemIndex。\n定义如下基本结构：\n1 2 3 4 5 type MemIndexShard[K comparable, V any] struct { shardCount int shards []storage2.MemIndex[K, V] sync.RWMutex } 然后是实例化部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func NewMemIndexShard[K comparable, V any](\\* ... *\\) *MemIndexShard[K, V] { index := \u0026amp;MemIndexShard[K, V]{ shardCount: shardCount, shards: make([]storage2.MemIndex[K, V], shardCount), } for i := 0; i \u0026lt; shardCount; i++ { switch memIndexType { case storage2.BTree: if btreeDegree \u0026lt;= 0 { ... } if btreeLessFunc == nil { ... } index.shards[i] = NewBTreeIndex[K, V](btreeDegree, btreeLessFunc) case storage2.SkipList: if skipListLessFunc == nil { ... } if skipListRandSource == nil { index.shards[i] = NewSkipListIndex[K, V](skipListLessFunc) } else { index.shards[i] = NewSkipListIndex[K, V](skipListLessFunc, WithRandSource(skipListRandSource)) } case storage2.SwissTable: if swissTableSize \u0026lt;= 0 { swissTableSize = 1 \u0026lt;\u0026lt; 10 } index.shards[i] = NewSwissIndex[K, V](swissTableSize) default: log.Fatal(\u0026#34;Unsupported memIndex type\u0026#34;) } } return index } 然后是分片操作，我们对 key 进行哈希然后对 shardCount 取模，得到对应的分片索引：\n1 2 3 4 5 func (s *MemIndexShard[K, V]) getShard(key K) storage2.MemIndex[K, V] { h := fnv.New32a() h.Write([]byte(fmt.Sprintf(\u0026#34;%v\u0026#34;, key))) return s.shards[h.Sum32()%uint32(s.shardCount)] } 然后就是 Put，Get，Del 操作，不难想到这里的流程如下：\ngetShard 获取 key 对应的分片。 shard 执行 Put，Get，Del 操作。 返回结果。 这里不多赘述，Foreach 操作也是同理，唯一的区别是需要遍历所有 shard。\n最后我们想想 Clear 操作，它是可以对所有 shard 并发执行的，所以实现上稍微有些不一样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 func (s *MemIndexShard[K, V]) Clear() error { s.Lock() defer s.Unlock() var wg sync.WaitGroup errChan := make(chan error, len(s.shards)) defer close(errChan) for _, shard := range s.shards { wg.Add(1) go func(s storage2.MemIndex[K, V]) { defer wg.Done() if err := s.Clear(); err != nil { errChan \u0026lt;- err } }(shard) } wg.Wait() select { case err := \u0026lt;-errChan: return fmt.Errorf(\u0026#34;could not clear index: %w\u0026#34;, err) default: return nil } } LRUCache \u0026amp; BloomFilter 首先我们想想，目前的实现下，我们读取所有数据都需要进行以下流程：\n每次读取都需要进行磁盘 IO，显然效率非常低下。但是在一个系统中，显然不可能所有数据被使用的概率都是等可能的，必然存在有一些热点数据的情况。\n那么对于这些使用频率较高的热点数据，我们考虑使用缓存来进行加速。\n引入缓存后，我们读取时会先询问缓存中是否存在这个数据，如果存在则直接返回，否则再去磁盘中读取。这样就可以减少一些不必要的磁盘 IO，提高效率。\n现在的流程如下：\n下一步就是怎么确定哪些数据是热点数据。\n我们这里使用 LRU 实现缓存，在 LRU 中，我们认为最近被访问过的数据将有更高的概率被再次访问，所以我们将这些数据作为热点数据放到缓存中。\n这里对于 LRU 的实现不做赘述。\n然后我们继续考虑，是否可以进一步减少不必要的磁盘 IO。\n此前我们引入了内存缓存，但缓存是有容量限制的，现在我们考虑，假设现在有大量恶意的请求，这些请求的 key 都不在内存缓存中或者不在整个存储中，那么这些请求将会全部穿透到磁盘中，导致大量的磁盘 IO。\n为了避免这种情况，我们引入 BloomFilter 来进行过滤，对于确定不存在的 key，我们直接返回，对于可能存在的 key，我们再去缓存或者磁盘中查询。\n这样就避免了我们上面提到的场景可能会出现的问题。\n这里额外提一个自认为比较有意思的实现：\nBitcask 中的数据量是不确定的，但 BloomFilter 需要一个确定的最大容量。但是我又不想在初始设置一个极大的容量，这样显然会造成浪费。\n然后想到之前学习的 Go Slice 的实现，将它的扩容机制稍微修改应用在了这里：当前 BloomFilter 填充率大于 0.75 时，扩容一倍。\n这部分实现如下：\n1 2 3 4 5 6 // 检查是否需要扩容 if bf.autoScale \u0026amp;\u0026amp; float64(atomic.LoadUint64(\u0026amp;bf.n))/float64(bf.m) \u0026gt; growthThreshold { if err := bf.grow(); err != nil { return fmt.Errorf(\u0026#34;bloom filter grow failed: %v\u0026#34;, err) } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func (bf *ShardedBloomFilter) grow() error { newShardCount := uint32(len(bf.shards) * growthFactor) newShardBits := bf.shardBits * growthFactor newShards := make([]shard, newShardCount) for i := range newShards { newShards[i].bits = make([]uint64, newShardBits/64) } for i := 0; i \u0026lt; len(bf.shards); i++ { shard := \u0026amp;bf.shards[i] shard.Lock() shard.bits = make([]uint64, newShardBits/64) shard.Unlock() } bf.shards = newShards bf.m = uint64(newShardCount) * uint64(newShardBits) bf.shardMask = newShardCount - 1 bf.shardBits = newShardBits return nil } 至此，存储层的大部分内容就完成了。Bye~\n","date":"2025-02-10T19:58:06+08:00","permalink":"https://finntew.github.io/p/fincas-kv-storage-design-and-impl/","title":"FincasKV - 存储层设计与实现"},{"content":"最近参与了字节跳动青训营寒假专场的后端方向，结营项目 \u0026ldquo;抖音电商\u0026rdquo; 订单服务中有一项定时取消订单的功能需求，在这里记录一些我的想法和 demo 实现。\n一、前言 为了避免在用户在未确认(支付)的情况下一直占用商品库存，提高整体库存周转率，避免无效订单数据长时间驻留在缓存中，我们需要采用一些机制进行资源回收，在这里即为定时取消机制。我们为订单设置一个过期时间，当订单在过期时间内未确认支付时，自动取消订单释放库存。这一需求可以通过 RabbitMQ 消息队列实现。\n二、实现方案 我们先梳理一下在用户创建订单后的整个流程：\n我们需要实现的部分即：\u0026ldquo;定时取消订单\u0026rdquo; 子图部分，有如下两种实现方案：\n1) 使用死信交换机配合死信队列实现 一些介绍 死信交换机(DLX)\n死信交换机即一个专门用于接收死信的交换机。当消息成为死信后，它们会被路由到指定的死信交换机。根据配置，交换机可以将这些死信消息路由到一个或多个死信队列中。\n工作流程：\n创建队列时配置交换机及相关属性参数。 当消息在正常队列中因为一些原因(消息过期；达到最大重试次数；队列限制)无法被消费时，被标记为死信。 标记的死信根据配置发送到设置的死信交换机。 死信交换机根据路由规则将死信发送到对应的死信队列。 死信队列(DLQ)\n死信队列即一个特殊的队列，用于存储那些不能被正常处理的消息(因为上文描述的原因标记为死信的消息)。\nDemo 实现 参照上文我们发现，过期的消息会被标记为死信发送到死信交换机，在轮转到死信队列。\n那么我们不难想到这里的第一个方案：创建一个死信交换机，过期的消息被发送到死信交换机，然后创建一个死信队列，接收过期的死信，最后创建一个消费者，消费死信队列中的消息，即可实现定时取消订单的功能。\n然后就是 Coding 实现想法了。\n这里先使用 Docker Compose 搭建一个 RabbitMQ 环境，方便后续的测试：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 version: \u0026#39;3\u0026#39; services: rabbitmq: image: rabbitmq:3-management container_name: rabbitmq-test ports: - \u0026#34;5672:5672\u0026#34; - \u0026#34;15672:15672\u0026#34; environment: RABBITMQ_DEFAULT_USER: finn RABBITMQ_DEFAULT_PASS: finn volumes: - rabbitmq_data:/var/lib/rabbitmq volumes: rabbitmq_data: 首先定义以下订单结构，方便后续的模拟：\n1 2 3 4 5 6 7 8 9 10 11 type Order struct { ID string `json:\u0026#34;id\u0026#34;` Status string `json:\u0026#34;status\u0026#34;` CreatedAt time.Time `json:\u0026#34;created_at\u0026#34;` } const ( StatusPending = \u0026#34;pending\u0026#34; StatusSuccess = \u0026#34;success\u0026#34; StatusClosed = \u0026#34;closed\u0026#34; ) 连接到 RabbitMQ：\n1 2 3 4 5 6 conn, err := amqp.Dial(\u0026#34;amqp://finn:finn@localhost:5672/\u0026#34;) // ... defer conn.Close() ch, err := conn.Channel() //... defer ch.Close() 然后按照流程创建交换机、队列：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 func declareExchanges(ch *amqp.Channel) error { // 声明普通交换机 err := ch.ExchangeDeclare( normalExchange, \u0026#34;direct\u0026#34;, true, false, false, false, nil, ) // ... // 声明延迟交换机 err = ch.ExchangeDeclare( delayExchange, \u0026#34;direct\u0026#34;, true, false, false, false, nil, ) // ... // 声明死信交换机 err = ch.ExchangeDeclare( deadLetterExchange, \u0026#34;direct\u0026#34;, true, false, false, false, nil, ) return err } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 func declareQueues(ch *amqp.Channel) error { // 声明普通队列 _, err := ch.QueueDeclare( normalQueue, true, false, false, false, nil, ) //... // 绑定普通队列 err = ch.QueueBind( normalQueue, normalKey, normalExchange, false, nil, ) //... // 声明延迟队列 args := amqp.Table{ \u0026#34;x-dead-letter-exchange\u0026#34;: deadLetterExchange, \u0026#34;x-dead-letter-routing-key\u0026#34;: deadLetterKey, \u0026#34;x-message-ttl\u0026#34;: int32(orderTTL.Milliseconds()), } _, err = ch.QueueDeclare( delayQueue, true, false, false, false, args, ) //... // 绑定延迟队列 err = ch.QueueBind( delayQueue, delayKey, delayExchange, false, nil, ) //... // 声明死信队列 _, err = ch.QueueDeclare( deadLetterQueue, true, false, false, false, nil, ) //... // 绑定死信队列 err = ch.QueueBind( deadLetterQueue, deadLetterKey, deadLetterExchange, false, nil, ) return err } 最后即消费者的实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 func consumeNormalQueue(ch *amqp.Channel) { msgs, err := ch.Consume( normalQueue, \u0026#34;\u0026#34;, false, false, false, false, nil, ) //... for msg := range msgs { var order Order err := json.Unmarshal(msg.Body, \u0026amp;order) if err != nil { //... msg.Ack(false) continue } // 改变订单状态，这里随机模拟 if rand.Float32() \u0026lt; 0.3 { order.Status = StatusSuccess } //... // 轮转发送到延迟队列 ctx := context.Background() publishOrder(ctx, ch, delayExchange, delayKey, order) msg.Ack(false) } } func consumeDeadLetterQueue(ch *amqp.Channel) { msgs, err := ch.Consume( deadLetterQueue, \u0026#34;\u0026#34;, false, false, false, false, nil, ) //... for msg := range msgs { var order Order err := json.Unmarshal(msg.Body, \u0026amp;order) if err != nil { //... msg.Ack(false) continue } // 检查订单状态 if order.Status == StatusPending { order.Status = StatusClosed log.Printf(\u0026#34;Order %s timeout, status changed to %s\u0026#34;, order.ID, order.Status) } else { log.Printf(\u0026#34;Order %s status is %s, no change needed\u0026#34;, order.ID, order.Status) } msg.Ack(false) } } 最后在主函数模拟用户创建订单即可完成整个流程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 模拟创建订单 ctx := context.Background() for i := 1; i \u0026lt;= 5; i++ { order := Order{ ID: fmt.Sprintf(\u0026#34;ORDER_%d\u0026#34;, i), Status: StatusPending, CreatedAt: time.Now(), } // 发送到普通队列 publishOrder(ctx, ch, normalExchange, normalKey, order) time.Sleep(2 * time.Second) } // 启动消费者 forever := make(chan struct{}) go consumeNormalQueue(ch) go consumeDeadLetterQueue(ch) \u0026lt;-forever 其中省略了一些不关键的错误处理和日志输出，最终效果如下：\n1 2 3 4 5 2025/01/19 16:51:06 Order ORDER_1 timeout, status changed to closed 2025/01/19 16:51:06 Order ORDER_2 status is success, no change needed 2025/01/19 16:51:06 Order ORDER_3 status is success, no change needed 2025/01/19 16:51:06 Order ORDER_4 status is success, no change needed 2025/01/19 16:51:06 Order ORDER_5 status is success, no change needed 可以看到，订单在过期时间内未确认支付时，自动取消订单确实已经完成。\n但是我们继续考虑这种实现可能会导致的问题：\n当订单满足超时条件需要取消时，我们需要轮转消息到死信队列，之后在死信队列中重新处理，这可能会造成延迟，导致实际取消时间超出预设的时间。 大量订单消息轮转到死信队列中，造成消息积压，可能导致负载增加，系统性能下降。 业务逻辑肉眼可见的变得复杂，不易于维护。 显然需要进行一些优化，这里引出我们的第二种实现方案：\n2) 使用延时队列插件实现 RabbitMQ 提供了一个延时队列插件 rabbitmq_delayed_message_exchange。我们可以依赖这个插件实现定时取消。\n一些介绍 延迟消息交换机是一种特殊的交换机，允许用户将消息在指定的时间延迟后再发送到目标队列。这种机制适用于需要在未来某个时刻处理的消息场景，例如定时任务、延迟通知等。\n工作流程：\n创建延迟消息交换机时，指定其类型为 x-delayed-message，并设置所需的参数。 发布消息时，可以在消息的属性中设置延迟时间（以毫秒为单位）。 消息在指定的延迟时间后，交换机会将其路由到相应的目标队列。 消费者从目标队列中获取到延迟后的消息进行处理。 Demo 实现 我们首先在之前开启的 RabbitMQ 服务中引入这个插件：\n下载插件：\n1 mkdir -p ~/rabbitmq/plugins \u0026amp;\u0026amp; wget -P ~/rabbitmq/plugins https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases/download/v3.13.0/rabbitmq_delayed_message_exchange-3.13.0.ez Copy 到容器：\n1 sudo docker cp ~/rabbitmq/plugins/rabbitmq_delayed_message_exchange-3.13.0.ez rabbitmq-test:/plugins 启动插件：\n1 sudo docker exec -it rabbitmq-test rabbitmq-plugins enable rabbitmq_delayed_message_exchange 重启服务：\n1 sudo docker restart rabbitmq-test 然后开始调整一下代码实现：\n只需要修改一下创建队列和交换机的部分即可，其他部分不变：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 // 声明普通交换机 err := ch.ExchangeDeclare( normalExchange, \u0026#34;direct\u0026#34;, true, false, false, false, nil, ) // 声明延时交换机（使用 delayed-message-exchange 插件） args := amqp.Table{ \u0026#34;x-delayed-type\u0026#34;: \u0026#34;direct\u0026#34;, } err = ch.ExchangeDeclare( delayedExchange, \u0026#34;x-delayed-message\u0026#34;, true, false, false, false, args, ) // 声明普通队列 _, err = ch.QueueDeclare( normalQueue, true, false, false, false, nil, ) // 绑定普通队列 err = ch.QueueBind( normalQueue, normalKey, normalExchange, false, nil, ) // 声明延时队列 _, err = ch.QueueDeclare( delayedQueue, true, false, false, false, nil, ) // 绑定延时队列 err = ch.QueueBind( delayedQueue, delayedKey, delayedExchange, false, nil, ) 三、总结 比较项 rabbitmq_delayed_message_exchange 死信队列和死信交换机 超时取消延迟 无需轮转消息，直接在预设时间后处理，避免延迟，精准控制取消时间 需要轮转到死信队列，处理延迟可能导致实际取消时间超出预设时间 消息积压 消息在延迟交换机中处理，避免积压，系统性能更稳定 大量订单消息轮转到死信队列，可能导致消息积压，增加系统负载，影响性能 业务逻辑复杂性 逻辑简单，易于理解和维护，直观的延迟处理机制 业务逻辑复杂，需处理死信队列重试和转发，增加维护成本和复杂度 系统性能 高效处理，减少资源消耗，优化整体性能 可能因消息积压导致系统性能下降，影响其他业务流程 配置和管理 配置简单，无需额外设置死信队列，减少管理负担 需要配置和管理死信队列及交换机，增加运维复杂度 灵活性 可以灵活设置不同的延迟时间，适应多种业务场景 灵活性有限，重试逻辑和延迟处理需要额外设计 ","date":"2025-01-18T22:01:51+08:00","permalink":"https://finntew.github.io/p/order-scheduled-cancel-by-rabbitmq/","title":"字节青训营 - [抖音电商项目] 使用 RabbitMQ 实现订单定时取消"},{"content":"今天早上终于考完了该亖的操作系统期末，记录以下最近刚刚开始的开源贡献之旅 ～\n如果以前大胆一些的话应该一年前就已经开始了吧（后悔实录\u0026hellip;逃）。\n早在去年年末的时候就有机会参与开源，但因为自己说不清的技术恐惧一拖再拖，直到今年 10 月底才开始自己在 Apache Seata-Go 项目的第一次贡献。\n刚开始参与进来大概只是因为年底找实习体验实在不好，想以此丰富一下简历，后来随着不断学习和贡献的过程，逐渐被社区氛围所吸引，开始意识到这本身就是一件非常有意义的事情。\n第一次贡献 开始的前几周只是参与了社区周会，并没有做什么实际的贡献，大多时间在熟悉代码和相关的 Samples 上。\n直到 11.24 才第一次提交了代码，优化 buildLockKey 的时间复杂度，因为基本没有和别的逻辑相关联，对于新手来说比较友好。\n仅仅是通过预处理的方式将时间复杂度从 $O(N \\times M \\times K)$ 降低到 $O(N \\times K)$ 。\n在这之后就是基本保持在一周提交一个 PR 的频率，做了一些简单的 bug fix 和 更新文档 的工作。\n参与实现的第一个 feature 在最近几周社区开始了对 Saga 模式的支持，我也开始了自己的第一个 feature 任务：为 Saga 支持多类型配置。\n最初的想法是使用 Viper 来支持，但是实现时发现 Viper 在解析 json 和 yaml 时会自动的进行键名规范(模糊大小写，将其全部转化为小写)，但已有的 Saga StateMachine Parser 的实现是不模糊大小写的。\n所以需要进行一些修改，交流确认后决定使用 encoding/json 和 yaml.v3 代替掉 Viper 。\n然后需要对 State Machine Parser 进行简单调整以兼容两种格式，因为 encoding/json 和 yaml.v3 对数值的解析实现不同：\n之后修复了一些导致 State Machine Parser 解析失败的 bug，以及对 Config Parser 和 State Machine Parser 进行单测完善。\n(由于最近期末周的原因，State Machine Parser 的单测还没有修改完善）等期末结束后写完提交再调整一下细节大概就结束力！\nThat\u0026rsquo;s all!\n","date":"2024-12-25T21:00:14+08:00","permalink":"https://finntew.github.io/p/open-source-contribute-start/","title":"开源贡献 - 参与开源项目初尝试"},{"content":"前言 果然，每次期末周临近的时候都会感觉全世界的 DDL 都突然吻了上来(厄厄\u0026hellip;)。\n先展示一下这次课设我的选题吧：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 智能简历解析系统 1. 简历导入与管理 （1）支持格式：系统应支持常见的简历格式，包括但不限于Word（.doc, .docx）、PDF和纯文本（.txt）。 （2）导入方式：允许用户通过拖拽、点击上传等方式单个或批量提交简历。 （3）存储与检索：可按导入日期，文件名称等方式查询简历。可根据用户的选择，打开并显示一份简历文件。 2. 简历解析与结构化 （1）内容提取：自动从简历中提取求职者信息，如姓名、联系方式、教育背景、工作经历、技能等。 （2）数据结构化：为用户提供多种简历解析数据的格式，包括但不限于JSON、CSV、XML。 （3）格式转换：支持将解析后的一种简历数据格式转换为其他格式。 3. 简历匹配与筛选 （1）关键词匹配：允许用户设定关键词，系统根据关键词自动筛选符合条件的简历。 （2）语义匹配：利用NLP技术，实现简历与职位描述之间的语义匹配，提高筛选的准确性。 （3）技能评估：根据求职者简历中的技能描述，评估其技能熟练度，并给出相应的评分。 4. 数据分析与报告 （1）统计分析：对简历数据进行统计分析，如求职者年龄分布、学历分布、技能分布等。 （2）报告生成：提供可视化报告，以图表形式展示分析结果，并配以文字介绍。 还有另一个做 stp 零件仿真的选题，感觉对我来说太灾难了，遂放弃\u0026hellip;\n然后，点明表扬：整个项目里只需要保证至少 30% 的代码是 C# 实现即可！泰好！\n数据库设计 我们结合需求 1-(3) 以及需求 2-(1) 即可确定我们的数据库怎么设计，具体需要存储一些什么内容。\n首先我们需要一个主表，存储简历的基本特征，比如：\n上传时间，原文件名：方便检索 在服务器上的存储路径 文件格式：方便后续不同文件格式的内容读取 是否解析完成 解析后的json文本：方便后续人岗匹配 然后就是一些从表了，比如：\n基本信息 教育经历 工作经历 技能 项目经历 \u0026hellip; 通过外键 resume_id 和主表关联。\n后文会补充添加一些其他的表。\n需求实现记录 讲道理比较难实现的只有 解析和语义匹配 两部分，NLP 对非人工智能专业的鼠鼠还是太超前了。\n简历导入与管理 这里需求(1)(2)可以放在一起考虑，首先考虑前端实现。\nReact的话可以使用 useDropzone Hook 实现拖拽上传以及文件格式限制。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 const onDrop = useCallback( (acceptedFiles: File[], rejectedFiles: any[]) =\u0026gt; { if (rejectedFiles.length \u0026gt; 0) { setError(\u0026#39;只支持 PDF、DOC、DOCX、TXT 格式的文件\u0026#39;); setTimeout(() =\u0026gt; setError(null), 3000); return; } onFileUpload(acceptedFiles); }, [onFileUpload] ); const { getRootProps, getInputProps, isDragActive } = useDropzone( { onDrop, accept: { \u0026#39;application/pdf\u0026#39;: [\u0026#39;.pdf\u0026#39;], \u0026#39;application/msword\u0026#39;: [\u0026#39;.doc\u0026#39;], \u0026#39;application/vnd.openxmlformats-officedocument.wordprocessingml.document\u0026#39;: [\u0026#39;.docx\u0026#39;], \u0026#39;text/plain\u0026#39;: [\u0026#39;.txt\u0026#39;] }, multiple: true, onDragEnter: () =\u0026gt; setDragCount(prev =\u0026gt; prev + 1), onDragLeave: () =\u0026gt; setDragCount(prev =\u0026gt; prev - 1) } ); 然后后端实现就比较简单了，遍历 context.Request.Form.Files 然后验证文件类型之后，保存文件到服务器上即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 async (HttpContext context) =\u0026gt; { var formFiles = context.Request.Form.Files; if (formFiles.Count == 0) { return Results.Json(new { success = false, message = \u0026#34;No files were uploaded.\u0026#34; }, statusCode: StatusCodes.Status400BadRequest); } string[] supportedFormats = [\u0026#34;.doc\u0026#34;, \u0026#34;.docx\u0026#34;, \u0026#34;.pdf\u0026#34;, \u0026#34;.txt\u0026#34;]; var uploadedFiles = new List\u0026lt;string\u0026gt;(); foreach (var formFile in formFiles) { // 检查文件格式 if (!supportedFormats.Any(x =\u0026gt; formFile.FileName.EndsWith(x, StringComparison.OrdinalIgnoreCase))) { return Results.Json(new { success = false, message = $\u0026#34;Unsupported file format: {formFile.FileName}\u0026#34; }, statusCode: StatusCodes.Status400BadRequest); } // 处理 \u0026amp; 保存文件 var fileExtension = Path.GetExtension(formFile.FileName); var timestamp = DateTime.Now.ToString(\u0026#34;yyyyMMddHHmmssfff\u0026#34;); var newFileName = $\u0026#34;{Path.GetFileNameWithoutExtension(formFile.FileName)}-{timestamp}{fileExtension}\u0026#34;; var filePath = Path.Combine(Directory.GetCurrentDirectory(), \u0026#34;Uploads\u0026#34;, newFileName); await using (var stream = new FileStream(filePath, FileMode.Create)) { await formFile.CopyToAsync(stream); } // 存入数据库 // 将解析任务置入消息队列 uploadedFiles.Add(newFileName); } return Results.Json(new { success = true, uploadedFiles }, statusCode: StatusCodes.Status200OK); } 消息队列这里在后面的解析部分详细解释。\n然后需求(3)就很简单了，我们数据库里已经存储了上传时间，文件名这些用于检索的字段，检索时筛选一下时间区间内的行 or 模糊查询一下文件名字段即可。\n1 2 3 4 -- 按照时间筛选 SELECT * FROM resumes WHERE upload_date BETWEEN \u0026#39;开始时间\u0026#39; AND \u0026#39;结束时间\u0026#39;; -- 使用文件名查找 SELECT * FROM resumes WHERE file_name LIKE \u0026#39;%内容%\u0026#39;; 可以进行一些简单的优化：\n比如为 upload_date 字段添加索引 1 ALTER TABLE resumes ADD INDEX idx_upload_date (upload_date); 为 file_name 字段添加全文索引(这里其实并不太需要) 1 ALTER TABLE resumes ADD FULLTEXT(file_name); 然后我们可以使用全文搜索代替原本的模糊查询 1 SELECT * FROM resumes WHERE MATCH(file_name) AGAINST(\u0026#39;内容\u0026#39; IN NATURAL LANGUAGE MODE); 简历解析与结构化 对于需求(1)的内容提取，查阅资料发现一般做法是使用 NLP 实现，对内容进行 NER 标识后做对应的提取工作。\n感觉很难在 DDL 前速成并实现出来(悲)，所以我们这里另辟蹊径，给大模型提供相应的 prompt，让它帮我们完成解析工作，并严格规范其输出格式为 JSON。\n这里我使用的 prompt 如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 请阅读以下简历文本，提取并整理出以下信息，且尽可能的使用原文信息，并以 JSON 格式返回： - **个人信息**：姓名、手机号、邮箱、微信、博客、GitHub 等。 - **教育经历**（数组）：每个元素包括学校名称、时间区间、专业等。 - **竞赛经历**（数组，可选）：每个元素包括竞赛名称、时间、奖项等。 - **项目经历**（数组）：每个元素包括项目名称、技术栈、时间、介绍、亮点等。 - **工作经历**（数组）：每个元素包括公司名称、职位、工作内容、时间等。 - **专业技能**（数组）：每个元素包括技能描述、熟练度等。 - **荣誉/证书**（数组，可选）：每个元素仅为一个荣誉/证书字符串。 - **技术栈标签**（数组，可选）：每个元素仅为一个技术名称字符串。 **要求**： - 确保提取的信息准确无误。 - 输出格式为 JSON。 - 时间格式统一为 `YYYY-MM` 或 `YYYY-MM-DD`。 **示例输出**： \\`\\`\\`json { \u0026#34;personal_info\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;张三\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;13800000000\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;zhangsan@example.com\u0026#34;, \u0026#34;wechat\u0026#34;: \u0026#34;zhangsan_wechat\u0026#34;, \u0026#34;blog\u0026#34;: \u0026#34;https://zhangsan.blog\u0026#34;, \u0026#34;github\u0026#34;: \u0026#34;https://github.com/zhangsan\u0026#34; }, \u0026#34;education\u0026#34;: [ { \u0026#34;school\u0026#34;: \u0026#34;清华大学\u0026#34;, \u0026#34;degree\u0026#34;: \u0026#34;本科\u0026#34;, \u0026#34;major\u0026#34;: \u0026#34;计算机科学\u0026#34;, \u0026#34;start_date\u0026#34;: \u0026#34;2015-09\u0026#34;, \u0026#34;end_date\u0026#34;: \u0026#34;2019-07\u0026#34; } ], \u0026#34;competitions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;ACM 国际大学生程序设计竞赛\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2018-05\u0026#34;, \u0026#34;award\u0026#34;: \u0026#34;银牌\u0026#34; } ], \u0026#34;projects\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;智能推荐系统\u0026#34;, \u0026#34;start_date\u0026#34;: \u0026#34;2019-08\u0026#34;, \u0026#34;end_date\u0026#34;: \u0026#34;2020-06\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;开发了一款基于机器学习的智能推荐系统。\u0026#34;, \u0026#34;highlights\u0026#34;: \u0026#34;提高了用户点击率20%\u0026#34; } ], \u0026#34;work_experience\u0026#34;: [ { \u0026#34;company\u0026#34;: \u0026#34;百度\u0026#34;, \u0026#34;position\u0026#34;: \u0026#34;高级研发工程师\u0026#34;, \u0026#34;responsibilities\u0026#34;: \u0026#34;负责搜索算法的优化和维护。\u0026#34;, \u0026#34;start_date\u0026#34;: \u0026#34;2020-07\u0026#34;, \u0026#34;end_date\u0026#34;: \u0026#34;2023-10\u0026#34; } ], \u0026#34;skills\u0026#34;: [ { \u0026#34;skill\u0026#34;: \u0026#34;Python 编程\u0026#34;, \u0026#34;proficiency\u0026#34;: \u0026#34;精通\u0026#34; } ], \u0026#34;certificates\u0026#34;: [\u0026#34;CET-4\u0026#34;, \u0026#34;CET-6\u0026#34;], \u0026#34;tech_tags\u0026#34;: [\u0026#34;Python\u0026#34;, \u0026#34;机器学习\u0026#34;], } \\`\\`\\` 以下是简历文本： \\`\\`\\`text {resumeContent} \\`\\`\\` 测试了几次后发现效果还是不错的。\n然后这里就有了一个新的问题，调用大模型做解析是一个比较耗时的操作，测试时大概需要 20s 左右才可以得到结果，显然让用户一直等待是不可取的。\n所以在上个需求上传时我们将解析任务放入消息队列中等待，然后直接反馈结果给用户，将解析任务延迟到消费者中执行，这样用户就可以直接进行其他操作而非一直等待直到解析完成。\n然后就是消费者的实现，比较显然了：\n调用大模型，等待响应 处理大模型输出 解析json 修改主表 parsed 字段，将json文本存入主表(方便后文语义匹配) 将解析后对应的内容存入对应的从表中 4和5放在一个事务中执行即可。\n然后格式转换这里也就比较简单了，因为我们主表中存储了json文本，所以直接查询主表后用一些工具库将json文本转换成别的格式(如csv, xml)即可。\n简历匹配与筛选 先看需求(1)，这里我们使用 ElasticSearch 实现，每次项目启动时，将主表中 parsed 字段为 true 行的 resume_id 和 parsed_data 字段映射到 ElasticSearch 中，然后利用 ElasticSearch 的 bool 查询即可。\n这里使用 must 匹配(必须和若干个关键词全部匹配)和 should 匹配(和关键词中的任意一个匹配即可)。\n然后对匹配结果在主表中通过 resume_id 字段进行筛选展示即可。\n然后对于需求(2)，我的实现是综合考虑文本相似度和结构化数据相似度，然后进行加权计算。\n这里需要对岗位JD先进行解析，和简历解析实现方式基本一致，不多赘述了。\n文本语义匹配：我们将json处理为纯文本，然后利用 BERT 模型提取岗位JD和简历的语义向量，然后计算二者的余弦相似度，即可量化其语义相关性，注意对其归一化处理，余弦相似度取值范围为 [-1, 1]，我们对其进行归一化处理得到一个 [0, 1] 的值，值越大表示越相关。 结构化数据匹配：我们对岗位JD和简历中的学历，技能，工作经历等结构化信息，通过对比和比例得分的方式量化其匹配程度，同样的最后对其归一化处理，得到一个 [0, 1] 区间内的值。 最终加权计算：我们对上述两个值进行加权求和，得到一个 [0, 1] 区间内的值，值越大表示越相关，这里权的设置需要考虑二者哪个计算更准确，我这里的实现是 $ 0.6 \\times TextSimilarity + 0.4 \\times StructuredScore $，因为测试时结构化匹配的误差比语义相似度大的多。 完整流程如下：\n数据加载 \u0026amp; 初始化 解析resume和jd的json文本为字典格式 初始化模型和分词器 加载停用词表，可以从这个仓库下载 goto456/stopwords 初始化 jieba 分词器 初始化 BERT 模型，这里使用 google-bert/bert-base-chinese 文本数据处理 将resume 和 job 的 json 分别处理合并为两段纯文本，方便进行文本相似度计算 文本预处理：使用 jieba 分词器进行分词，去除停用词，并拼接为一个无空格的字符串 示例： 1 2 3 words = jieba.lcut(text) words = [word for word in words if word not in self.stopwords and word.strip() != \u0026#39;\u0026#39;] return \u0026#39;\u0026#39;.join(words) 文本相似度计算 将预处理后的文本通过 BERT 编码，获取语义向量表示，提取 [CLS] token 的向量作为文本的语义表示 示例： 1 2 3 inputs = self.tokenizer(text, return_tensors=\u0026#39;pt\u0026#39;, truncation=True, max_length=512).to(self.device) outputs = self.bert_model(**inputs) sentence_vector = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()[0] 计算余弦相似度，并归一化处理 $$ \\text{TextSimilarity} = \\frac{\\frac{\\vec{vec1} \\cdot \\vec{vec2}}{\\|\\vec{vec1}\\| \\cdot \\|\\vec{vec2}\\|} + 1}{2} $$ 结构化数据匹配 从学历，技能，工作经历等考虑匹配，计算得分，我这里只考虑了三个维度，设定满分为3，每个维度1分，最后计算比例得分得到一个 [0, 1] 的得分。 可以考虑尽可能多的维度，以获得更准确的匹配结果 最终得分计算 对文本相似度和结构化数据匹配的得分进行加权计算，得到最终的匹配得分 $$ \\text{Score} = 0.6 \\times \\text{TextSimilarity} + 0.4 \\times \\text{StructuredScore} $$ 最后的技能评估可以直接map映射一下 {熟练度,分数} 即可，因为json文本里已经很清楚了，这里不多赘述了。\n数据分析与报告 这部分也比较简单，可以使用一些图表展示库进行可视化报告，比如 echarts。\n后端只需要计算一下总数和不同类别的数量，向前端发送一个json描述这些信息，然后前端使用 echarts 进行展示即可。\n文本描述可以使用老配方(bushi)，调用大模型即可，prompt大法好！\nThat\u0026rsquo;s all!\n","date":"2024-11-21T20:24:56+08:00","permalink":"https://finntew.github.io/p/jd-resume-match/","title":"课程设计 - 智能简历解析系统"},{"content":"BloomFilter 工作原理 \u0026amp; 优/缺点 BloomFilter 本质上就是由一个二进制位数组和一系列的哈希函数组成的一个集合数据结构，特殊的点在于，和其他集合数据结构不同，我们并不会在 BloomFilter 中直接存储集合中的元素，而是在位数组中记录每个元素的存在性。\n工作原理：\n插入时，对当前插入的目标对象计算多次哈希值，得到 $Object \\rightarrow IndexOfBinaryArray$ 的映射，将这些下标置1。 查找时，同理对当前插入的目标对象计算多次哈希值，得到 $Object \\rightarrow IndexOfBinaryArray$ 的映射，判断这些下标是否全部为1。 这样做的好处是：\n占用空间少。 插入以及查询时间复杂度都非常低，为 $O(Cnt_{HashFunc})$。 但相应的缺点也非常明显：\n查询得到的结果是概率性正确的，而非绝对正确。 删除困难。 且缺点随着 BloomFilter 中存放对象数量的增加而扩大。\n不过可以保证的是：BloomFilter 查询得到存在性为否时，该对象确保不在集合里。\n类似于：如果某天下雨，那么老寒腿的人前一天一定腿疼了，但是老寒腿的人腿疼的时候第二天并不一定会下雨。\nBloomFilter 也是这样，得到某个对象不存在的结果时一定正确，但得到某个对象存在的结果时只是有正确的概率，并不保证一定正确。\n需要注意的是：我们选择哈希函数的 seed 时，注意素数距离的同时尽可能选择接近 2 的幂的素数，尽可能的使得哈希分布均匀。\n使用场景 存在性判定： 判断某个元素是否在一个很大数据量的集合中。 防止缓存穿透：判断请求数据是否有效避免直接绕过缓存请求数据库等。 垃圾邮箱过滤：判断目标邮箱是否在垃圾邮件列表中。 黑名单判定：判断IP / 手机号等等是否在黑名单中。 短链接过滤：判断某个短链是否已经被使用。 \u0026hellip; 去重： 爬虫的目标 URL 去重。 订单号去重。 \u0026hellip; 实现 定义 \u0026amp; Hash 我们前面提到 \u0026ldquo;BloomFilter 本质上就是由一个二进制位数组和一系列的哈希函数组成的一个集合数据结构\u0026rdquo;。\n显然需要我们需要设置如下四个字段：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type BloomFilter[Type comparable] struct { bitset []bool // 位数组 size int // 位数组大小 hashes int // 哈希函数个数 seeds [14]int // 哈希函数使用的 seed } func NewBloomFilter[Type comparable]() *BloomFilter[Type] { return \u0026amp;BloomFilter[Type]{ bitset: make([]bool, 2\u0026lt;\u0026lt;24), size: 2 \u0026lt;\u0026lt; 24, hashes: 14, seeds: [14]int{3, 13, 47, 67, 89, 137, 193, 257, 331, 421, 521, 631, 761, 907}, } } 哈希函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func hash(value interface{}, seed, cap int) (int, error) { if value == nil { return 0, fmt.Errorf(\u0026#34;value is nil\u0026#34;) } hasher := fnv.New32a() _, err := hasher.Write([]byte(fmt.Sprintf(\u0026#34;%v\u0026#34;, value))) if err != nil { return 0, fmt.Errorf(\u0026#34;unable to hasher value: %w\u0026#34;, err) } h := int(hasher.Sum32()) result := ((cap-1)\u0026amp;seed*(h^(h\u0026gt;\u0026gt;16)) + cap) % cap // 确保到下标的映射不会越界 if result \u0026lt; 0 { return -result, nil } return result, nil } 新增 \u0026amp; 查询 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func (bf *BloomFilter[Type]) Add(value Type) { for i := 0; i \u0026lt; bf.hashes; i++ { index, err := hash(value, bf.seeds[i], bf.size) if err != nil { panic(err) } bf.bitset[index] = true // 修改位数组 } } func (bf *BloomFilter[Type]) Contains(value Type) (bool, error) { result := true for i := 0; i \u0026lt; bf.hashes; i++ { index, err := hash(value, bf.seeds[i], bf.size) if err != nil { return false, err } result = result \u0026amp;\u0026amp; bf.bitset[index] } return result, nil } ","date":"2024-10-28T13:15:46+08:00","permalink":"https://finntew.github.io/p/bloomfliter-impl/","title":"DataStructure - BloomFilter 实现"},{"content":"常见垃圾回收策略 引用计数(Reference Counting) 引用计数算法是一种简单的垃圾回收算法，C++ 中 std::shared_ptr 就使用了这种算法。\n基本思想：给对象添加一个引用计数字段，每当有一个地方引用它时，计数加1，引用失效时，计数减1,当计数为0时，意味着对象不再被使用，可以对其进行回收。\n优点是：\n不需要从根节点遍历，相对容易查找。 每个对象知道自己被引用的次数，一旦引用计数为0，就将其连接到空闲链表上等待回收。 在 Mutator 更新引用计数时就会触发垃圾回收，不需要等待内存耗尽的时机，因此不会出现程序暂停时间过久的问题。 缺点也比较明显：\n无法解决循环引用问题。 我们前面提到，每次使用都需要更新计数器，这会引起额外的开销。 需要额外的空间存储计数器。 追踪回收(Tracing Garbage Collection) 追踪回收算法有三种策略：标记-清除，标记-复制，标记-整理。\n需要注意的是，我们在引用计数中提到其不会出现程序暂停时间过长的问题，但对于追踪回收算法，这三种策略都需要 STW(Stop The World)，暂停程序执行。\n标记-清除(Mark-Sweep) 工作原理：\n从根对象出发递归遍历所有的可达对象，将可达对象标记为存活对象。 遍历堆中所有对象，对所有未标记对象进行回收。 优点是：\n可以解决引用计数存在的循环引用问题。 不需要使用额外的空间存储计数器。 但相应的：\n在清除阶段会产生大量碎片，导致内存碎片化，可能会导致程序分配对象时找不到连续的内存空间而再次触发垃圾回收。 执行效率不稳定。 标记-复制(Mark-Copying) 工作原理：\n从根对象出发递归遍历所有可达对象，将可达对象标记为存活对象。 将堆划分为两个相等的区域，一半为使用区，另一半为未使用区。 在程序运行时只将对象放到使用区，使用区满时，执行垃圾回收，遍历所有使用区的对象，判断其存活状态并将存活对象移动到未使用区，完成后清空使用区，最后交换两块区域的角色。 优点：\n解决内存碎片化问题：每次执行垃圾回收机制都会将存活对象移动到未使用区，对象保证连续存放。 执行效率相对较高：只需要复制存活对象，清除未存活对象时批量操作，徐啊哟的时间相对较短，吞吐率更高。 快速分配内存：因为内存分布是连续的，所以分配内存时只需要移动指针即可，相比其他算法使用空闲链表的做法，连续内存分配效率更高。 缺点：\n空间利用率低：相同内存空间的条件下只有一半空间可以用于存放对象。 递归效率低：需要递归遍历复制所有可达对象，相较于迭代效率较低，且需要额外的栈开销，可能会造成内存溢出。 标记-整理(Mark-Compact) 工作原理：\n从根对象出发，递归遍历所有可达对象，将可达对象标记为存活对象。 将存活对象移至堆的一端，然后清除未存活对象。 优点：\n空间利用率高 相对于标记-复制策略来说，空间利用率更高，不会浪费一半的空间。 缺点：\n执行效率低：将存活对象移动到堆的一端时需要进行三次遍历，需要花费更多的时间，当对象数量足够多时，暂停时间远大于其他两种策略。 对比 吞吐率：标记-复制 \u0026gt; 标记-整理 \u0026gt; 标记-清除 内存利用率：标记-整理 \u0026gt; 标记-清除 \u0026gt; 标记-复制 内存整齐度：标记-整理 = 标记-复制 \u0026gt; 标记-清除 Golang GC 三色标记法 三色标记改进了标记-清除算法，将标记-清除的两个阶段分解为三个阶段(标记，标记终止，标记清除)，减少了 STW 时间。\n三色标记：\n白色：未访问对象，未被访问的对象可能是需要回收的对象。 灰色：访问中对象，已被访问的对象，但其子对象未被访问。 黑色：已访问对象，已被访问的对象，其子对象也已被访问。 最终被回收的对象是白色标记的对象。\n工作原理：\n开始时将对象标记为灰色。 在灰色对象中选择一个将其标记为黑色，然后将其子对象标记为灰色。 将黑色对象指向的所有白色对象标记为灰色。 重复上述2,3步骤 清除所有白色对象 如图：\n如果不进行 STW 会发生什么？\n实际上，如果正常的按照三色标记法进行 STW，其 STW 的时间依旧比较长。但是如果不进行 STW，在标记和清除的过程中，程序可能会继续运行，这个过程中可能会造成对象的状态发生变化，从而导致垃圾回收器无法正确标记对象的状态，导致回收发生错误。 如图，假设 A D 遍历完成后，在到达 B 之前，如果 D 添加了对 C 的引用，B 移除了对 C 的引用，那么 C 在 GC 之后会变为白色，被回收。\n屏障技术 为了解决上面的问题，Golang 引入的屏障技术，可以在对象状态发生变化时及时通知垃圾回收器。\n需要注意的是，为了在并发或者增量标记算法中保证标记的正确性，需要达成一种三色不变性：\n强三色不变性：标记阶段中，黑色对象不会指向白色对象。 弱三色不变性：标记阶段中，黑色对象指向的白色对象(G)必须包含一条包含一条灰色对象经过一个或者多个白色对象后到达白色对象(G)的路径。 如图：\n如果 A 添加了对 D 的引用，那么 E 需要再向 D 添加引用保证弱三色不变性。\n插入屏障 在 Golang 中，当一个对象 A 添加了对另一个对象 B 的引用时，会在 A 的引用列表中插入一个 B 的引用，并将 B 标记为灰色。\n需要注意：出于对性能问题的考虑，插入屏障只会在堆上生效，而不会在栈上生效。\n如图：\n如上图所示，在初始条件下，A 属于栈上数据，F 属于堆上数据，在2中同时向 A 添加 D 的引用，向 F 添加 H 的引用，H 由于插入屏障会变成灰色，而 D 不在堆上不会变为灰色，当扫描完成后，4中 H 会被标记为灰色，D 被标记为白色，此时 STW 启动将栈上的对象重新扫描一遍，将 D 标记为黑色。\n删除屏障 当一个对象 A 删除了对另一个对象 B 的引用时，会在 A 的引用列表中删除一个 B 的引用，如果 B 是白色的则将其标记为灰色。\n如图：\n将白色对象标记为灰色，是因为白色对象在之后可能还会被其他对象引用，如果不标记为灰色，可能会导致后续的扫描无法被扫描到。\n混合写屏障 上面提到的插入屏障和删除屏障有一些缺点：\n插入屏障在扫描结束后还需要 STW 一次，将栈上的对象重新扫描一遍。 删除屏障回收精度较低，在回收开始时需要 STW 一次，将栈上的对象重新扫描一遍，记录初始快照，保护初始时刻所有存活对象。 为了解决这些问题，Golang 引入了混合写屏障，是插入屏障和删除屏障的结合，可以在对象状态发生变化时通知垃圾回收器。\n工作原理：\n垃圾回收开始时，将栈上的对象全部扫描一遍并标记为黑色（不进行二次扫描）。 垃圾回收期间，任何栈上创建的对象都会标记为黑色，防止二次扫描。 垃圾回收期间，删除的所有对象都会标记为灰色。 垃圾回收期间，创建的所有对象都会标记为灰色。 ","date":"2024-10-27T12:56:56+08:00","permalink":"https://finntew.github.io/p/go-note-gc/","title":"Golang 笔记 - GC(垃圾回收机制)"},{"content":"Scheduler OS 内核和我们实际写的逻辑代码之间由 runtime 提供交互关系，runtime 调用 OS 的系统调用，OS 调用硬件资源，然后我们的程序得以运行。\nScheduler 即 负责调度 Goroutine 的模块，它根据一定的策略调度 Goroutine 的执行，保证 Goroutine 的执行顺序和并发度。\n这个过程使用的模型即为 GMP 模型。\nGMP 模型 GMP 模型是 Golang 调度器的核心模型，是 Golang 调度器的基础。\nGMP (Goroutine - Machine - Processor)：\nGoroutine: 一个协程，包括栈及相关的上下文信息。 Machine: 一个执行线程，负责将 Goroutine 映射到 OS 的线程上，每个 Machine 都有自己的调用栈和寄存器状态。 Processor: 一个逻辑处理器，维护一个处于可运行状态的 Goroutine 队列，每个 Machine 都与一个 Processor 关联。 如图：\n全局队列(GRQ)：存放所有正在等待运行的 Goroutine 的队列。 本地队列(LRQ)：存放当前 Processor 的可运行(包括正在运行和处于等待中)的 Goroutine 的队列，每个 Processor 都拥有一个本地队列，每个本地队列最大可以存放 256 个 Goroutine。 在 Goroutine 创建时会优先置于本地队列，本地队列存满时取出一半加入到全局队列。\n需要注意的是： Processor 的数量是固定的，由最大并发数决定，而 Machine 的数量是动态的，由调度器确定，根据当前负载情况动态调整。\nMachine 运行任务时需要获取 Processor，否则 Machine 会堵塞，如果 Processor 的本地队列为空，则 Machine 会从全局队列中获取 Goroutine 放入其对应的本地队列，如果全局队列为空，则随机从一个 Processor 的本地队列取出一半 Goroutine 放入对应 Processor 的本地队列。\n调度器策略 抢占式调度 对于 Goroutine，需要一个 Goroutine 让出 CPU 后下一个 Goroutine 才能使用 CPU。\n而 Golang 中规定每个 Goroutine 每次最多只能占用 10ms CPU，然后切换到其他 Goroutine，以此防止其他 Goroutine 长时间处于等待状态而不被执行。\n复用线程 Golang 的调度器会复用线程，而非每次创建新的线程，减少了线程创建和销毁的开销，有效提高性能。\n工作偷取(Working Stealing)：就像前面 \u0026ldquo;GMP模型\u0026rdquo; 部分提到的：当 Machine 没有可运行的 Goroutine 时，会尝试随机偷取其他 Processor 的本地队列内容，而非销毁 Machine。 挂起机制(hand Off)：当 Goroutine 因为系统调用的原因阻塞时，Machine 会释放与其对应的 Processor 供给其他 Machine 使用。 并行 通过最大并发数决定 Processor 的数量，实现并行执行，Processor 的数量决定了并行度，Processor 的数量等于 CPU 核心数时实现最大并行度。\n全局队列 参见复用线程策略的工作偷取机制：\n本地队列中没有可运行的 Goroutine 时， Machine 优先在全局队列尝试获取新的 Goroutine， 若全局队列中没有待运行状态的 Goroutine，则尝试偷取其他 Processor 对应的本地队列中的 Goroutine。\nGMP 调度流程 创建一个 Goroutine 时，如果存在未满的本地队列，则随机放入一个未满的本地队列，否则放入全局队列。\n执行 Goroutine 时，Processor 获取一个 Goroutine 在 Machine 中执行，如果此时 Goroutine 发生 SystemCall 导致的堵塞，则将 Machine 放入休眠队列，同时从中取出一个新的 Machine 接管 Processor 执行，如果休眠队列为空，则创建一个新的 Machine 用于接管。\n获取 Goroutine 的机制即 \u0026ldquo;工作偷取\u0026rdquo; 机制。\nMachine 的生命周期 参见：\n其中：\nM0：主线程创建的第一个线程，负责创建和运行第一个 Goroutine，存储在 runtime.m0 中，不需要在堆上分配。 G0：M0 创建之后立即创建一个 Goroutine 称为 G0，仅用于调度 Goroutine，不执行逻辑代码 G0 和 M0 相对应。\n","date":"2024-10-26T18:42:10+08:00","permalink":"https://finntew.github.io/p/go-note-gmp/","title":"Golang 笔记 - GMP 模型"},{"content":"比赛链接：牛客小白月赛 103 A. 冰冰的正多边形 思路 签到，选择任意数量的木棍拼多边形，显然周长最小的是正三角形，所以记录每种长度木棍的数量，答案即为 $Min_{i=1}^{n} {3*Len_i} (Cnt_{Len_i} \\geq 3)$，如果没有数量大于等于3的则为\u0026quot;no\u0026quot;，注意特判 $ n \\leq 2 $。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 func Solve() { defer func() { _ = writer.Flush() }() var n int _, _ = fmt.Fscan(reader, \u0026amp;n) cnt := make(map[int]int) for i := 0; i \u0026lt; n; i++ { var x int _, _ = fmt.Fscan(reader, \u0026amp;x) cnt[x] += 1 } if n \u0026lt;= 2 { _, _ = fmt.Fprintf(writer, \u0026#34;no\\n\u0026#34;) return } res := 100000000 for k, v := range cnt { if v \u0026lt; 3 { continue } res = min(res, k * 3) } if res == 100000000 { _, _ = fmt.Fprintf(writer, \u0026#34;no\\n\u0026#34;) return } _, _ = fmt.Fprintf(writer, \u0026#34;yes\\n%d\\n\u0026#34;, res) } B. 冰冰的电子邮箱 思路 模拟题，将 $s$ 按 \u0026ldquo;@\u0026rdquo; 分割为两个部分，分别检查 local_part 和 domain 部分是否合法即可。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 func Check(email string) bool { p := strings.Split(email, \u0026#34;@\u0026#34;) if len(p) != 2 { return false } lp, dm := p[0], p[1] if len(lp) \u0026lt; 1 || len(lp) \u0026gt; 64 { return false } if len(dm) \u0026lt; 1 || len(dm) \u0026gt; 255 { return false } if !CheckLP(lp) || !CheckDM(dm) { return false } return true } func CheckLP(lp string) bool { if lp[0] == \u0026#39;.\u0026#39; || lp[len(lp)-1] == \u0026#39;.\u0026#39; { return false } for _, ch := range lp { if !unicode.IsLetter(ch) \u0026amp;\u0026amp; !unicode.IsDigit(ch) \u0026amp;\u0026amp; ch != \u0026#39;.\u0026#39; { return false } } return true } func CheckDM(dm string) bool { if dm[0] == \u0026#39;.\u0026#39; || dm[len(dm)-1] == \u0026#39;.\u0026#39; || dm[0] == \u0026#39;-\u0026#39; || dm[len(dm)-1] == \u0026#39;-\u0026#39; { return false } for _, ch := range dm { if !unicode.IsLetter(ch) \u0026amp;\u0026amp; !unicode.IsDigit(ch) \u0026amp;\u0026amp; ch != \u0026#39;.\u0026#39; \u0026amp;\u0026amp; ch != \u0026#39;-\u0026#39; { return false } } return true } func Solve() { defer func() { _ = writer.Flush() }() var s string _, _ = fmt.Fscan(reader, \u0026amp;s) if Check(s) { fmt.Fprintln(writer, \u0026#34;Yes\u0026#34;) } else { fmt.Fprintln(writer, \u0026#34;No\u0026#34;) } } C. 冰冰的异或 思路 找规律，模拟题目操作打表可以发现:\n$ n \\leq 2 $ 时，答案为 1。 $ n \u0026gt; 2$ 时，答案为大于等于 n 的第一个2的幂。 打表代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func Test() { defer func() { _ = writer.Flush() }() for n := 1; n \u0026lt;= 100; n++ { vis := make(map[int]struct{}) for i := 1; i \u0026lt;= n; i++ { for j := 1; j \u0026lt;= n; j++ { vis[i^j] = struct{}{} } } for i := 0; i \u0026lt;= n*2; i++ { if _, ok := vis[i]; !ok { _, _ = fmt.Fprintf(writer, \u0026#34;N = %d, Ans = %d\\n\u0026#34;, n, i) break } } } } 代码 1 2 3 4 5 6 7 8 9 10 11 12 func Solve() { defer func() { _ = writer.Flush() }() var n int _, _ = fmt.Fscan(reader, \u0026amp;n) if n \u0026lt;= 2 { _, _ = fmt.Fprintln(writer, 1) } else { _, _ = fmt.Fprintln(writer, 1\u0026lt;\u0026lt;bits.Len(uint(n-1))) } } D. 冰冰的分界线 思路 易知，题目要求的分界线即为两点连线的中垂线，考虑到实数精度问题，考虑计算点集里点两两之间的中垂线方程的一般式，用 map 去重，其长度即为答案。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 type Line struct { a, b, c int } func gcd(a, b int) int { if b == 0 { return a } return gcd(b, a%b) } func calc(a, b, c int) (int, int, int) { if a \u0026lt; 0 || (a == 0 \u0026amp;\u0026amp; b \u0026lt; 0) { a, b, c = -a, -b, -c } g := gcd(gcd(abs(a), abs(b)), abs(c)) return a / g, b / g, c / g } func abs(x int) int { if x \u0026lt; 0 { return -x } return x } func Solve() { defer func() { _ = writer.Flush() }() var n int _, _ = fmt.Fscan(reader, \u0026amp;n) x := make([]int, n) y := make([]int, n) for i := 0; i \u0026lt; n; i++ { _, _ = fmt.Fscan(reader, \u0026amp;x[i]) } for i := 0; i \u0026lt; n; i++ { _, _ = fmt.Fscan(reader, \u0026amp;y[i]) } l := make(map[Line]struct{}) for i := 0; i \u0026lt; n; i++ { for j := i + 1; j \u0026lt; n; j++ { a, b, c := 2*(x[j]-x[i]), 2*(y[j]-y[i]), y[j]*y[j]-y[i]*y[i]+x[j]*x[j]-x[i]*x[i] a, b, c = calc(a, b, c) l[Line{a, b, c}] = struct{}{} } } _, _ = fmt.Fprintln(writer, len(l)) } ","date":"2024-10-25T21:32:40+08:00","permalink":"https://finntew.github.io/p/nowcoder-month-103/","title":"题解 - 牛客小白月赛 103"},{"content":"一些介绍 我们知道，数组是由确定长度的相同类型元素的集合组成的一种数据结构，整体占用一片连续的内存空间。\n1 2 3 4 5 6 7 8 9 10 11 arr := [5]int{2, 4, 6, 8, 10} curr := unsafe.Pointer(\u0026amp;arr[0]) end := unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;arr[0]))+unsafe.Sizeof(*new(int))*uintptr(5)) for { if curr == end { break } print(*(*int)(curr), \u0026#34; \u0026#34;) curr = unsafe.Pointer(uintptr(curr) + unsafe.Sizeof(*new(int))) }\tprintln() 上面的代码可以验证这一点，而对于确定长度和相同类型，可以参照源代码 cmd/compile/internal/types/type.go 中的 types.NewArray 实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /* * type Array struct { * Elem *Type * Bound int64 * } */ func NewArray(elem *Type, bound int64) *Type { if bound \u0026lt; 0 { base.Fatalf(\u0026#34;NewArray: invalid bound %v\u0026#34;, bound) } t := newType(TARRAY) t.extra = \u0026amp;Array{Elem: elem, Bound: bound} if elem.HasShape() { t.SetHasShape(true) } if elem.NotInHeap() { t.SetNotInHeap(true) } return t } 且对于 是否在堆栈中初始化 也是在编译期就确定了，由数组存储元素的类型决定。\n数组初始化 创建 在 Golang 中，数组有 [Len]Type{elems...} 和 [...]Type{elems...} 两种创建方式。前者显式的指定长度，后者在编译期推导其长度。\n两种方式构造的数组在运行时是完全相同的。\ncmd/compile/internal/typecheck/expr.go typecheck.tcCompLit\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func tcCompLit(n *ir.CompLitExpr) (res ir.Node) { //... t := n.Type() //... switch t.Kind() { default: base.Errorf(\u0026#34;invalid composite literal type %v\u0026#34;, t) n.SetType(nil) case types.TARRAY: typecheckarraylit(t.Elem(), t.NumElem(), n.List, \u0026#34;array literal\u0026#34;) n.SetOp(ir.OARRAYLIT) //... } //... return n } 最终都会通过 typecheckarraylit 函数计算实际长度/检查是否越界。[...]Type 只是一种提供便利的语法糖。\n优化 编译器会根据数组元素数量的范围进行不同的优化：\n$len \u0026gt; 4$ 时，先获取一个保证唯一的 staticname，在静态存储区上初始化数组的元素，然后拷贝到栈上。 cmd/compile/internal/walk/complit.go walk.anylit\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func anylit(n ir.Node, var_ ir.Node, init *ir.Nodes) { t := n.Type() switch t.Kind() { //... case ir.OSTRUCTLIT, ir.OARRAYLIT: n := n.(*ir.CompLitExpr) if !t.IsStruct() \u0026amp;\u0026amp; !t.IsArray() { base.Fatalf(\u0026#34;anylit: not struct/array\u0026#34;) } if isSimpleName(var_) \u0026amp;\u0026amp; len(n.List) \u0026gt; 4 { // lay out static data vstat := readonlystaticname(t) ctxt := inInitFunction if n.Op() == ir.OARRAYLIT { ctxt = inNonInitFunction } fixedlit(ctxt, initKindStatic, n, vstat, init) // copy static to var appendWalkStmt(init, ir.NewAssignStmt(base.Pos, var_, vstat)) // add expressions to automatic fixedlit(inInitFunction, initKindDynamic, n, var_, init) break } //... } } 可以理解为下面这样：\n1 2 3 4 5 6 7 8 9 var arr [5]int //... staticname_var_0[0] = 1 staticname_var_0[1] = 2 staticname_var_0[2] = 3 staticname_var_0[3] = 4 staticname_var_0[4] = 5 //... arr = staticname_var_0 $len \\leq 4$ 时，将其转化为更原始的语句，并将元素直接放在栈上。 cmd/compile/internal/walk/complit.go walk.anylit\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func anylit(n ir.Node, var_ ir.Node, init *ir.Nodes) { t := n.Type() switch t.Kind() { //... case ir.OSTRUCTLIT, ir.OARRAYLIT: n := n.(*ir.CompLitExpr) if !t.IsStruct() \u0026amp;\u0026amp; !t.IsArray() { base.Fatalf(\u0026#34;anylit: not struct/array\u0026#34;) } if isSimpleName(var_) \u0026amp;\u0026amp; len(n.List) \u0026gt; 4 { //... break } var components int64 if n.Op() == ir.OARRAYLIT { components = t.NumElem() } else { components = int64(t.NumFields()) } // initialization of an array or struct with unspecified components (missing fields or arrays) if isSimpleName(var_) || int64(len(n.List)) \u0026lt; components { appendWalkStmt(init, ir.NewAssignStmt(base.Pos, var_, nil)) } fixedlit(inInitFunction, initKindLocalCode, n, var_, init) } } cmd/compile/internal/walk/complit.go walk.fixedlit\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func fixedlit(ctxt initContext, kind initKind, n *ir.CompLitExpr, var_ ir.Node, init *ir.Nodes) { isBlank := var_ == ir.BlankNode var splitnode func(ir.Node) (a ir.Node, value ir.Node) //... for _, r := range n.List { a, value := splitnode(r) if a == ir.BlankNode \u0026amp;\u0026amp; !staticinit.AnySideEffects(value) { // Discard. continue } islit := ir.IsConstNode(value) if (kind == initKindStatic \u0026amp;\u0026amp; !islit) || (kind == initKindDynamic \u0026amp;\u0026amp; islit) { continue } // build list of assignments: var[index] = expr ir.SetPos(a) as := ir.NewAssignStmt(base.Pos, a, value) as = typecheck.Stmt(as).(*ir.AssignStmt) switch kind { case initKindStatic: genAsStatic(as) case initKindDynamic, initKindLocalCode: appendWalkStmt(init, orderStmtInPlace(as, map[string][]*ir.Name{})) default: base.Fatalf(\u0026#34;fixedlit: bad kind %d\u0026#34;, kind) } } } 可以理解为下面这样：\n1 2 3 4 5 var arr [4]int arr[0] = 1 arr[1] = 2 arr[2] = 3 arr[3] = 4 访问 \u0026amp; 赋值 介绍部分的代码已经有所验证：数组是一片连续的内存空间(无论是在栈上还是静态存储区)，已知首指针、长度、元素类型的size就可以确定整个数组。\n访问 通过索引访问数组元素时，会基于首地址加上索引乘以元素大小快速定位到特定元素。\nGolang 在编译期以及运行时都会进行越界检查，确保访问合法。\n赋值 同理，当我们对数组中的某个元素赋值时，新值直接存储到计算的对应内存地址。\n需要注意的是，数组赋值给另一个数组时会复制整个数组，因为数组是值类型。这意味着每次赋值都会创建一个新的数组副本。\n同样在其传递时也会复制数组本身，采用值传递的方式。\n","date":"2024-10-19T19:31:17+08:00","permalink":"https://finntew.github.io/p/go-note-array/","title":"Golang 笔记 - 数组的底层实现"},{"content":"我们不难想到，对于路由的组织可以按照如下的树状结构：\n对于每个结点，其子结点拥有相同的前缀。\n这一点和 Trie (字典树/前缀树) 不谋而合。\n所以我们可以考虑用 Trie 来实现一个基础的路由树。\nTrie 实现 结构定义 对于一个基本的 Trie 结点，我们可以这样定义：\n1 2 3 4 5 type TreeNode struct { next map[rune]*TreeNode val rune isEnd bool } 但是，对于路由来说，我们需要记录更多的信息，比如最基本的：\n为了实现动态路由，我们需要记录路由参数，比如：/user/:id 中的 :id，所以，我们需要记录一下路由参数的键。 对于每个路径，我们希望它绑定到一个具体的处理方法，比如：/user/:id 绑定到 UserMethod。 所以对于一个基本的路由树结点，定义如下:\n1 2 3 4 5 6 7 type TreeNode struct { next map[rune]*TreeNode val rune isEnd bool method MethodType paramKey string } 完整的定义部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 type MethodType func(params map[string]string) error type TreeNode struct { next map[rune]*TreeNode val rune isEnd bool method MethodType paramKey string } type Router struct { root *TreeNode } func newTreeNode(val rune) *TreeNode { return \u0026amp;TreeNode{ next: make(map[rune]*TreeNode), val: val, isEnd: false, method: nil, paramKey: \u0026#34;\u0026#34;, } } func NewRouter() *Router { return \u0026amp;Router{ root: newTreeNode(\u0026#39;+\u0026#39;), } } 插入路由 插入路由的过程就是向Trie树中插入新的字符串的过程。\n不同之处在于，对于路径的处理，我们需要一些额外的处理，包括分割符和动态参数的键。\n参照上文结构定义，显然，分割符在树的结构上已经有所体现，不需要单独占用结点，而对于动态参数，我们只需要一个结点记录通配符 :，标记该位置为动态参数即可，而不需要为键名新建结点。\n明确了这些，就可以大胆 Coding 了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 func (t *Router) Add(path string, method MethodType) error { if method == nil { return errors.New(\u0026#34;method cannot be nil\u0026#34;) } curr := t.root // 分割路径 parts := strings.Split(strings.Trim(path, \u0026#34;/\u0026#34;), \u0026#34;/\u0026#34;) for _, part := range parts { if part == \u0026#34;\u0026#34; { continue } // 动态参数，处理通配符 if part[0] == \u0026#39;:\u0026#39; { if _, ok := curr.next[\u0026#39;:\u0026#39;]; !ok { curr.next[\u0026#39;:\u0026#39;] = newTreeNode(\u0026#39;:\u0026#39;) // 创建通配符结点 } curr = curr.next[\u0026#39;:\u0026#39;] curr.paramKey = part[1:] // 记录参数键名 } else { // 静态参数，处理常规路径字符 for _, char := range part { if _, ok := curr.next[char]; !ok { curr.next[char] = newTreeNode(char) } curr = curr.next[char] } } } // 绑定方法 curr.isEnd = true curr.method = method return nil } 查找路由 查找也是同理，和插入不同的是，我们需要记录动态参数的值，以供给绑定的 Method 使用。\n处理方式也很简单，匹配时遇到通配符结点就跳过，并记录参数值，其余情况就正常匹配即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 func (t *Router) Search(path string) error { curr := t.root params := make(map[string]string) // 分割路径 parts := strings.Split(strings.Trim(path, \u0026#34;/\u0026#34;), \u0026#34;/\u0026#34;) // 匹配路径 for _, part := range parts { if part == \u0026#34;\u0026#34; { continue } // 处理常规路径匹配 if next, ok := curr.next[rune(part[0])]; ok { curr = next for _, char := range part[1:] { if next, ok := curr.next[char]; ok { curr = next } else { return errors.New(\u0026#34;path not found\u0026#34;) } } } else if next, ok := curr.next[\u0026#39;:\u0026#39;]; ok { // 处理动态参数，通配符匹配 curr = next params[curr.paramKey] = part // 记录参数值 } else { return errors.New(\u0026#34;path not found\u0026#34;) } } if !curr.isEnd { // 判断是否为完整路径 return errors.New(\u0026#34;path not found\u0026#34;) } if err := curr.method(params); err != nil { return err } return nil } 一些思考 可以发现，直接套用Trie实现的话，路径的每个part占用整条链的其中一部分，查找时不可避免的需要遍历整条链，每次的查找深度都是 $len(path)$。\n我们结合文章开始的图片 \u0026ldquo;Image 1\u0026rdquo; 可以想到：\n对于路由树来说，类似 \u0026ldquo;app\u0026rdquo;, \u0026ldquo;apple\u0026rdquo;, \u0026ldquo;art\u0026rdquo; 形成的如下树形结构：\n1 2 3 4 5 6 7 8 9 10 11 12 + root - a - p - p - ... - p - l - e - ... - r - t - ... 显然查找效率不如：\n1 2 3 4 5 6 7 + root - app - part... - art - part... - apple - part... 优化 结合上面提到的思路，我们不难想到，将路径的每个part作为一个结点。\n查找和插入的深度都会降低到 $Cnt_{part}(path)$。\n结构调整 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type MethodType func(params map[string]string) error type TreeNode struct { next map[string]*TreeNode // 字符结点 -\u0026gt; 路径片段结点 segment string // 字符 -\u0026gt; 路径片段 isEnd bool method MethodType paramKey string } type Router struct { root *TreeNode } func newTreeNode(segment string) *TreeNode { return \u0026amp;TreeNode{ segment: segment, next: make(map[string]*TreeNode), } } func NewRouter() *Router { return \u0026amp;Router{root: newTreeNode(\u0026#34;\u0026#34;)} } 插入路由 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func (r *Router) Add(path string, method MethodType) error { if method == nil { return errors.New(\u0026#34;method cannot be nil\u0026#34;) } // 分割路径 parts := strings.Split(strings.Trim(path, \u0026#34;/\u0026#34;), \u0026#34;/\u0026#34;) node := r.root for _, part := range parts { key := part if strings.HasPrefix(part, \u0026#34;:\u0026#34;) { key = \u0026#34;:\u0026#34; } // 创建结点 if _, exists := node.next[key]; !exists { node.next[key] = newTreeNode(part) } node = node.next[key] // 记录参数键名 if strings.HasPrefix(part, \u0026#34;:\u0026#34;) { node.paramKey = strings.TrimPrefix(part, \u0026#34;:\u0026#34;) } } // 绑定方法 node.isEnd = true node.method = method return nil } 查找路由 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func (r *Router) Search(path string) error { // 分割路径 parts := strings.Split(strings.Trim(path, \u0026#34;/\u0026#34;), \u0026#34;/\u0026#34;) node := r.root params := make(map[string]string) // 匹配路径 for _, part := range parts { if nextNode, exists := node.next[part]; exists { // 静态参数匹配 node = nextNode } else if nextNode, exists := node.next[\u0026#34;:\u0026#34;]; exists { // 动态参数匹配 node = nextNode params[node.paramKey] = part } else { // 匹配失败 return errors.New(\u0026#34;path not found\u0026#34;) } } // 判断是否为完整路径 if node.isEnd { return node.method(params) } return errors.New(\u0026#34;path not found\u0026#34;) } ","date":"2024-10-17T20:24:06+08:00","permalink":"https://finntew.github.io/p/router-tree-impl/","title":"DataStructure - 路由树的简单实现"},{"content":"比赛链接：牛客小白月赛 101 A. tb的区间问题 思路 签到，问题等价于求长度为k的连续子数组的最大和，预处理前缀和然后枚举左端点即可。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) var ( reader = bufio.NewReader(os.Stdin) writer = bufio.NewWriter(os.Stdout) ) func max(a, b int) int { if a \u0026gt; b { return a } return b } func Solve() { defer func() { _ = writer.Flush() }() var n, k int _, _ = fmt.Fscan(reader, \u0026amp;n, \u0026amp;k) arr := make([]int, n+1) preSum := make([]int, n+1) for i := 1; i \u0026lt;= n; i++ { _, _ = fmt.Fscan(reader, \u0026amp;arr[i]) preSum[i] = preSum[i-1] + arr[i] } res := 0 k = n - k for i := k + 1; i \u0026lt;= n; i++ { res = max(res, preSum[i]-preSum[i-k]) } _, _ = fmt.Fprintf(writer, \u0026#34;%d\\n\u0026#34;, res) } func main() { T := 1 //_, _ = fmt.Fscan(reader, \u0026amp;T) for i := 0; i \u0026lt; T; i++ { Solve() } } B. tb的字符串问题 思路 类似括号匹配问题，维护一个栈，如果栈顶元素为f且当前字符为c，则出栈，否则入栈，\u0026ldquo;tb\u0026quot;同理。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) var ( reader = bufio.NewReader(os.Stdin) writer = bufio.NewWriter(os.Stdout) ) func Solve() { defer func() { _ = writer.Flush() }() var ( n int str string ) _, _ = fmt.Fscan(reader, \u0026amp;n) _, _ = fmt.Fscan(reader, \u0026amp;str) stk := make([]rune, 0, n) for _, char := range str { length := len(stk) if length \u0026gt;= 1 { last := stk[length-1] if (last == \u0026#39;f\u0026#39; \u0026amp;\u0026amp; char == \u0026#39;c\u0026#39;) || (last == \u0026#39;t\u0026#39; \u0026amp;\u0026amp; char == \u0026#39;b\u0026#39;) { stk = stk[:length-1] continue } } stk = append(stk, char) } _, _ = fmt.Fprintf(writer, \u0026#34;%v\\n\u0026#34;, len(stk)) } func main() { T := 1 //_, _ = fmt.Fscan(reader, \u0026amp;T) for i := 0; i \u0026lt; T; i++ { Solve() } } C. tb的路径问题 思路 规律题，手玩一下样例，由 $gcd(a, b) = gcd(a, a-b)$，最近的路径为 $(1, 1) \\rightarrow (2, 2) \\rightarrow (2k-2, 2k)$，特判一下$n$比较小的情况。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) var ( reader = bufio.NewReader(os.Stdin) writer = bufio.NewWriter(os.Stdout) ) func Solve() { defer func() { _ = writer.Flush() }() var n int _, _ = fmt.Fscan(reader, \u0026amp;n) if n \u0026lt;= 3 { _, _ = fmt.Fprintln(writer, (n - 1) * 2) return } if n % 2 == 0 { _, _ = fmt.Fprintln(writer, 4) return } _, _ = fmt.Fprintln(writer, 6) } func main() { T := 1 //_, _ = fmt.Fscan(reader, \u0026amp;T) for i := 0; i \u0026lt; T; i++ { Solve() } } D. tb的平方问题 思路 题目问和为完全平方数且包含 $x$ 的区间个数，所以需要处理两个信息：完全平方数，对应区间。\n完全平方数我们可以 $O(\\sqrt{Max(a)})$ 的求出。\n而对于区间，注意到 $n \\in [1, 1000]$，可以直接枚举，复杂度为 $O(n^2)$。\n但是显然不能在线的去回答每次询问，考虑预处理，维护一个差分数组 $diff$，我们预处理完全平方数以及$a$的前缀和，然后枚举所有区间，对于每个区间，判断其和是否为完全平方数，是则更新差分数组 $[l, r]$ 区间。\n对于每个询问的答案即为 $diff[x]$。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) var ( reader = bufio.NewReader(os.Stdin) writer = bufio.NewWriter(os.Stdout) ) func Solve() { defer func() { _ = writer.Flush() }() var n, q int _, _ = fmt.Fscan(reader, \u0026amp;n, \u0026amp;q) arr := make([]int, n+1) preSum := make([]int, n+1) for i := 1; i \u0026lt;= n; i++ { _, _ = fmt.Fscan(reader, \u0026amp;arr[i]) preSum[i] = preSum[i-1] + arr[i] } vis := make(map[int]struct{}) val := 1 for val*val \u0026lt;= preSum[n] { vis[val*val] = struct{}{} val += 1 } diff := make([]int, n+1) insert := func(l, r int) { diff[l] += 1 if r \u0026lt; n { diff[r+1] -= 1 } } for l := 1; l \u0026lt;= n; l++ { for r := l; r \u0026lt;= n; r++ { sum := preSum[r] - preSum[l-1] if _, ok := vis[sum]; ok { insert(l, r) } } } for i := 1; i \u0026lt;= n; i++ { diff[i] += diff[i-1] } for q \u0026gt; 0 { var x int _, _ = fmt.Fscan(reader, \u0026amp;x) _, _ = fmt.Fprintln(writer, diff[x]) q -= 1 } } func main() { T := 1 // _, _ = fmt.Fscan(reader, \u0026amp;T) for i := 0; i \u0026lt; T; i++ { Solve() } } E. tb的数数问题 思路 找到所有没有出现过的数及其倍数，除去这些数，剩余的数的个数即为答案。\n类似埃氏筛写法，时间复杂度为调和级数。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) var ( reader = bufio.NewReader(os.Stdin) writer = bufio.NewWriter(os.Stdout) ) func max(a, b int) int { if a \u0026gt; b { return a } return b } func Solve() { defer func() { _ = writer.Flush() }() var n int _, _ = fmt.Fscan(reader, \u0026amp;n) arr := make([]int, n+1) vis := make(map[int]struct{}) flag := false maxVal := -1 for i := 1; i \u0026lt;= n; i++ { _, _ = fmt.Fscan(reader, \u0026amp;arr[i]) if arr[i] == 1 { flag = true } maxVal = max(maxVal, arr[i]) vis[arr[i]] = struct{}{} } if !flag { _, _ = fmt.Fprintln(writer, \u0026#34;0\u0026#34;) return } f := make(map[int]struct{}) for i := 2; i \u0026lt;= maxVal; i++ { _, isVis := vis[i] _, isF := f[i] if !isVis \u0026amp;\u0026amp; !isF { for j := 2*i; j \u0026lt;= maxVal; j += i { delete(vis, j) f[j] = struct{}{} } } } res := 0 for i := 1; i \u0026lt;= maxVal; i++ { if _, ok := vis[i]; ok { res += 1 } } _, _ = fmt.Fprintln(writer, res) } func main() { T := 1 //_, _ = fmt.Fscan(reader, \u0026amp;T) for i := 0; i \u0026lt; T; i++ { Solve() } } ","date":"2024-10-15T14:55:25+08:00","permalink":"https://finntew.github.io/p/nowcoder-month-101/","title":"题解 - 牛客小白月赛 101"},{"content":"比赛连接： 牛客周赛 63 A. 小红的好数 思路 签到，按字符串读入，先判断位数然后判断两位是否相等即可。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) var ( reader = bufio.NewReader(os.Stdin) writer = bufio.NewWriter(os.Stdout) ) func Solve() { defer func() { _ = writer.Flush() }() var x string _, _ = fmt.Fscan(reader, \u0026amp;x) if len(x) == 2 \u0026amp;\u0026amp; x[0] == x[1] { _, _ = fmt.Fprint(writer, \u0026#34;Yes\u0026#34;) } else { _, _ = fmt.Fprint(writer, \u0026#34;No\u0026#34;) } } func main() { T := 1 //_, _ = fmt.Fscan(reader, \u0026amp;T) for i := 0; i \u0026lt; T; i++ { Solve() } } B. 小红的好数组 思路 n, k 范围都只有 $[1, 1000]$，枚举左端点 $l \\in [0, n-k+1]$, 然后对于所有 $l$ 判断 $s[l:l+k]$ 是否可以恰好修改一位使得它回文即可。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) var ( reader = bufio.NewReader(os.Stdin) writer = bufio.NewWriter(os.Stdout) ) func Solve() { defer func() { _ = writer.Flush() }() var n, k int _, _ = fmt.Fscan(reader, \u0026amp;n, \u0026amp;k) arr := make([]int, n) for i := 0; i \u0026lt; n; i++ { _, _ = fmt.Fscan(reader, \u0026amp;arr[i]) } res := 0 for i := 0; i \u0026lt; n-k+1; i++ { l, r := i, i+k-1 cnt := 0 for l \u0026lt; r { if arr[l] != arr[r] { cnt += 1 } l += 1 r -= 1 } if cnt == 1 { res += 1 } } _, _ = fmt.Fprintf(writer, \u0026#34;%d\\n\u0026#34;, res) } func main() { T := 1 //_, _ = fmt.Fscan(reader, \u0026amp;T) for i := 0; i \u0026lt; T; i++ { Solve() } } C. 小红的矩阵行走 思路 问能否从左上角走到右下角，且下一个格子颜色必须与当前颜色一致。\nbfs 模拟题目要求即可，从 $(0, 0)$ 开始，每次向颜色相同的格子走，看是否可以到达 $(n-1, m-1)$ 即可。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) var ( reader = bufio.NewReader(os.Stdin) writer = bufio.NewWriter(os.Stdout) ) func Solve() { defer func() { _ = writer.Flush() }() var n, m int _, _ = fmt.Fscan(reader, \u0026amp;n, \u0026amp;m) a := make([][]int, n) for i := 0; i \u0026lt; n; i++ { a[i] = make([]int, m) for j := 0; j \u0026lt; m; j++ { _, _ = fmt.Fscan(reader, \u0026amp;a[i][j]) } } q := [][2]int{{0, 0}} for len(q) \u0026gt; 0 { x, y := q[0][0], q[0][1] if x == n-1 \u0026amp;\u0026amp; y == m-1 { _, _ = fmt.Fprintf(writer, \u0026#34;Yes\\n\u0026#34;) return } q = q[1:] for _, d := range [][2]int{{1, 0}, {0, 1}} { nx, ny := x+d[0], y+d[1] if nx \u0026lt; n \u0026amp;\u0026amp; ny \u0026lt; m \u0026amp;\u0026amp; a[nx][ny] == a[x][y] { q = append(q, [2]int{nx, ny}) } } } _, _ = fmt.Fprintf(writer, \u0026#34;No\\n\u0026#34;) } func main() { T := 1 _, _ = fmt.Fscan(reader, \u0026amp;T) for i := 0; i \u0026lt; T; i++ { Solve() } } D. 小红的行列式构造 思路 要构造一个值为 x 且所有元素都不为0的三阶行列式。\n换个想法，我们可以构造任意一个值为 1 的三阶行列式，然后乘以一个常数 x 即可。\n$$ A = \\left | \\begin{matrix} 1 \u0026 1 \u0026 1 \\\\ 1 \u0026 2 \u0026 1 \\\\ 1 \u0026 1 \u0026 2 \\end{matrix} \\right | = 1$$我们构造 $ x \\times A $ 即可，注意特判 $x = 0$ 时输出一个元素全部为 1 的行列式。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) var ( reader = bufio.NewReader(os.Stdin) writer = bufio.NewWriter(os.Stdout) ) func Solve() { defer func() { _ = writer.Flush() }() var x int _, _ = fmt.Fscan(reader, \u0026amp;x) if x == 0 { _, _ = fmt.Fprint(writer, \u0026#34;1 1 1\\n1 1 1\\n1 1 1\\n\u0026#34;) } else { _, _ = fmt.Fprintf(writer, \u0026#34;%d %d %d\\n1 2 1\\n1 1 2\\n\u0026#34;, x, x, x) } } func main() { T := 1 //_, _ = fmt.Fscan(reader, \u0026amp;T) for i := 0; i \u0026lt; T; i++ { Solve() } } E. 小红的 red 计数 说是线段树balabala的，待补\u0026hellip;\nF. 小红开灯 思路 首先，按照题意分别记录下所有同行/列的坐标，方便变换操作。\n对于每盏灯，我们按下他的同时，所有相关的灯置1，其他位置都置0，可以得到这个灯的状态01串。\n我们设 $ S_f[i] = S[i] \\oplus 1 $，则题目可以转化为，能否用求出的所有状态串凑出 $ S_f $。\n使用线性基维护所有状态，最后验证答案即可。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) var ( reader = bufio.NewReader(os.Stdin) writer = bufio.NewWriter(os.Stdout) ) const B = 100 type Bitset struct { bits [B + 1]bool } func (bs *Bitset) Reset() { for i := range bs.bits { bs.bits[i] = false } } func (bs *Bitset) Set(i int) { bs.bits[i] = true } func (bs *Bitset) Xor(other Bitset) { for i := range bs.bits { bs.bits[i] = bs.bits[i] != other.bits[i] } } func (bs *Bitset) HasBits() bool { for _, bit := range bs.bits { if bit { return true } } return false } type LinerBase struct { a []Bitset b [][]int cnt int } func NewLinerBase() *LinerBase { return \u0026amp;LinerBase{ a: make([]Bitset, B+1), b: make([][]int, B+1), } } func (lb *LinerBase) Insert(x Bitset, id int) int { v := []int{id} for i := B; i \u0026gt;= 0; i-- { if x.bits[i] { if !lb.a[i].HasBits() { lb.a[i] = x lb.b[i] = v lb.cnt++ return 1 } else { x.Xor(lb.a[i]) v = append(v, lb.b[i]...) } } } return 0 } func (lb *LinerBase) Size() int { return lb.cnt } func (lb *LinerBase) Ask(x Bitset) []int { var res []int for i := B; i \u0026gt;= 0; i-- { if x.bits[i] { x.Xor(lb.a[i]) res = append(res, lb.b[i]...) } } if x.HasBits() { return nil } return res } func Solve() { defer func() { _ = writer.Flush() }() var n int _, _ = fmt.Fscan(reader, \u0026amp;n) var str string _, _ = fmt.Fscan(reader, \u0026amp;str) str = \u0026#34; \u0026#34; + str xArr := make(map[int][]int) yArr := make(map[int][]int) p := make([][2]int, n+1) for i := 1; i \u0026lt;= n; i++ { var x, y int _, _ = fmt.Fscan(reader, \u0026amp;x, \u0026amp;y) xArr[x] = append(xArr[x], i) yArr[y] = append(yArr[y], i) p[i] = [2]int{x, y} } bs1 := Bitset{} lb := NewLinerBase() for i := 1; i \u0026lt;= n; i++ { x, y := p[i][0], p[i][1] bs1.Reset() for _, j := range xArr[x] { bs1.Set(j) } for _, j := range yArr[y] { bs1.Set(j) } lb.Insert(bs1, i) } bs2 := Bitset{} for i := 1; i \u0026lt;= n; i++ { if str[i] == \u0026#39;0\u0026#39; { bs2.Set(i) } } if strings.Count(str[1:], \u0026#34;1\u0026#34;) == n { _, _ = fmt.Fprintln(writer, \u0026#34;0\u0026#34;) return } res := lb.Ask(bs2) if res == nil { _, _ = fmt.Fprintln(writer, \u0026#34;-1\u0026#34;) } else { ans := make([]int, n+1) for _, i := range res { ans[i] ^= 1 } sum := 0 for i := 1; i \u0026lt;= n; i++ { if ans[i] != 0 { sum++ } } _, _ = fmt.Fprintln(writer, sum) for i := 1; i \u0026lt;= n; i++ { if ans[i] != 0 { _, _ = fmt.Fprintf(writer, \u0026#34;%d \u0026#34;, i) } } _, _ = fmt.Fprintln(writer) } } func main() { T := 1 //_, _ = fmt.Fscan(reader, \u0026amp;T) for i := 0; i \u0026lt; T; i++ { Solve() } } ","date":"2024-10-14T20:37:13+08:00","permalink":"https://finntew.github.io/p/nowcoder-week-63/","title":"题解 - 牛客周赛 63"},{"content":"一些介绍 ～ 底层结构 切片的底层结构如下：\n1 2 3 4 5 type slice struct { array unsafe.Pointer // 指向底层数组的指针 len int // 长度/当前元素个数 cap int // 容量/最大元素个数 } 可以看到 slice 本质上是从数组抽象出来的一个复合类型\n切片和数组的区别 这种设计使得切片相对数组更加灵活高效：\n长度、容量可以动态变化，可以追加元素，动态扩容 切片是一个引用类型，在传递时采用浅拷贝，只复制len和cap，而使用同一个底层数组 操作过程中更新len和cap，做到 $O(1)$ 的计算长度，而不像数组需要遍历计算长度 扩容机制 我们刚在提到切片可以追加元素，动态扩容\n所谓的扩容大致做法就是：当前长度加上追加元素的数量大于当前容量的时候，重新开一个新的满足长度要求的数组指针，将原数组元素依次拷贝到新数组后，再追加新的元素\n值的一提的是对于确定扩容后容量的做法，在1.18版本以前和1.18版本及以后版本的实现稍有不同：\n1.18 版本之前 期望的新容量大于当前容量的2倍：直接扩充为新容量 否则： 原容量小于1024：扩充为原来的2倍 原容量大于1024：循环若干次，每次扩充为原来的1.25倍，直到新容量大于等于期望容量为止 代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 newCap := s.capacity doubleCap := newCap + newCap if expCap \u0026gt; doubleCap { newCap = expCap } else { if s.capacity \u0026lt; 1024 { newCap = doubleCap } else { for 0 \u0026lt; newCap \u0026amp;\u0026amp; newCap \u0026lt; expCap { newCap += newCap / 4 } if newCap \u0026lt;= 0 { newCap = expCap } } } 由于这种扩容方式容量扩大不太平滑，循环扩容时会出现后一次的计算值比前一次的计算值小的情况，而且扩容后容量和长度差距过大\n所以在1.18版本之后，修改为了另一种更平滑的扩容方式，容量和长度也更加接近\n1.18 版本及之后版本 期望的新容量大于当前容量的2倍：直接扩充为新容量 否则： 原容量小于256：扩充为原来的2倍 原容量大于256：循环若干次，每次扩充增加 (旧容量+3*256)/4，直到新容量大于等于期望容量为止 代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 newCap := s.capacity doubleCap := newCap + newCap if expCap \u0026gt; doubleCap { newCap = expCap } else { if s.capacity \u0026lt; 256 { newCap = doubleCap } else { for 0 \u0026lt; newCap \u0026amp;\u0026amp; newCap \u0026lt; expCap { newCap += (newCap + 3*256) / 4 } if newCap \u0026lt;= 0 { newCap = expCap } } } 手写实现 ～ 结构定义 \u0026amp; 构造 \u0026hellip; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 type Slice[T any] struct { array unsafe.Pointer // 底层数组 length int // 长度 capacity int // 容量 } func NewSlice[T any](capacity int) *Slice[T] { arrPtr := unsafe.Pointer(\u0026amp;make([]T, capacity)[0]) return \u0026amp;Slice[T]{ array: arrPtr, length: 0, capacity: capacity, } } func (s *Slice[T]) Len() int { return s.length } func (s *Slice[T]) Cap() int { return s.capacity } func (s *Slice[T]) Array() []T { return (*(*[]T)(unsafe.Pointer(\u0026amp;s.array)))[:s.length] } 追加元素 1 2 3 4 5 6 7 8 9 10 func (s *Slice[T]) Append(elems ...T) { if s.length \u0026gt;= s.capacity { s.grow(s.length + 1) // 扩容 } for i := 0; i \u0026lt; len(elems); i++ { // 追加元素 elemPtr := unsafe.Pointer(uintptr(s.array) + uintptr(s.length)*unsafe.Sizeof(*new(T))) *(*T)(elemPtr) = elems[i] s.length += 1 // 更新长度 } } 扩容 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 func (s *Slice[T]) grow(expCap int) { newCap := s.capacity doubleCap := newCap + newCap // 1.18 以前 //if expCap \u0026gt; doubleCap { //\tnewCap = expCap //} else { //\tif s.capacity \u0026lt; 1024 { //\tnewCap = doubleCap //\t} else { //\tfor 0 \u0026lt; newCap \u0026amp;\u0026amp; newCap \u0026lt; expCap { //\tnewCap += newCap / 4 //\t} //\tif newCap \u0026lt;= 0 { //\tnewCap = expCap //\t} //\t} //} // 1.18 及以后 // 计算新容量 if expCap \u0026gt; doubleCap { newCap = expCap } else { if s.capacity \u0026lt; 256 { newCap = doubleCap } else { for 0 \u0026lt; newCap \u0026amp;\u0026amp; newCap \u0026lt; expCap { newCap += (newCap + 3*256) / 4 } if newCap \u0026lt;= 0 { newCap = expCap } } } // 创新新的底层数组 newArrPtr := unsafe.Pointer(\u0026amp;make([]T, newCap)[0]) // 拷贝元素 for i := 0; i \u0026lt; s.length; i++ { oldElemPtr := unsafe.Pointer(uintptr(s.array) + uintptr(i)*unsafe.Sizeof(*new(T))) newElemPtr := unsafe.Pointer(uintptr(newArrPtr) + uintptr(i)*unsafe.Sizeof(*new(T))) *(*T)(newElemPtr) = *(*T)(oldElemPtr) } // 更新指针 s.array = newArrPtr s.capacity = newCap } 取值 \u0026amp; 修改 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func (s *Slice[T]) Get(idx int) T { if idx \u0026lt; 0 || idx \u0026gt;= s.length { panic(\u0026#34;index out of range\u0026#34;) } elemPtr := unsafe.Pointer(uintptr(s.array) + uintptr(idx)*unsafe.Sizeof(*new(T))) return *(*T)(elemPtr) } func (s *Slice[T]) Set(idx int, elem T) { if idx \u0026lt; 0 || idx \u0026gt;= s.length { panic(\u0026#34;index out of range\u0026#34;) } elemPtr := unsafe.Pointer(uintptr(s.array) + uintptr(idx)*unsafe.Sizeof(*new(T))) *(*T)(elemPtr) = elem } 截取 \u0026amp; 删除 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 func (s *Slice[T]) Slice(leftBound, rightBound int) *Slice[T] { // 检查区间合法性 if leftBound \u0026lt; 0 || rightBound \u0026gt; s.length || leftBound \u0026gt; rightBound { panic(\u0026#34;invalid slice bounds\u0026#34;) } // 创建新的切片 return \u0026amp;Slice[T]{ // 这里只需要将向左边界偏移后的指针设为新切片的起始指针即可 array: unsafe.Pointer(uintptr(s.array) + uintptr(leftBound)*unsafe.Sizeof(*new(T))), length: rightBound - leftBound, capacity: s.capacity - leftBound, } } func (s *Slice[T]) Del(idx int) { if idx \u0026lt; 0 || idx \u0026gt;= s.length { panic(\u0026#34;index out of range\u0026#34;) } // 删除操作：拼接 [0, idx) 和 (idx, s.length-1]两个切片即可 newArrPtr := s.Slice(0, idx) newArrPtr.Append(s.Slice(idx+1, s.length).Array()...) s.array = newArrPtr.array s.length -= 1 s.capacity = newArrPtr.capacity } 完整代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 package my import \u0026#34;unsafe\u0026#34; type Slice[T any] struct { array unsafe.Pointer // 底层数组 length int // 长度 capacity int // 容量 } func NewSlice[T any](capacity int) *Slice[T] { arrPtr := unsafe.Pointer(\u0026amp;make([]T, capacity)[0]) return \u0026amp;Slice[T]{ array: arrPtr, length: 0, capacity: capacity, } } func (s *Slice[T]) Len() int { return s.length } func (s *Slice[T]) Cap() int { return s.capacity } func (s *Slice[T]) Array() []T { return (*(*[]T)(unsafe.Pointer(\u0026amp;s.array)))[:s.length] } func (s *Slice[T]) Append(elems ...T) { if s.length \u0026gt;= s.capacity { s.grow(s.length + 1) } for i := 0; i \u0026lt; len(elems); i++ { elemPtr := unsafe.Pointer(uintptr(s.array) + uintptr(s.length)*unsafe.Sizeof(*new(T))) *(*T)(elemPtr) = elems[i] s.length += 1 } } func (s *Slice[T]) grow(expCap int) { newCap := s.capacity doubleCap := newCap + newCap // 1.18 以前 //if expCap \u0026gt; doubleCap { //\tnewCap = expCap //} else { //\tif s.capacity \u0026lt; 1024 { //\tnewCap = doubleCap //\t} else { //\tfor 0 \u0026lt; newCap \u0026amp;\u0026amp; newCap \u0026lt; expCap { //\tnewCap += newCap / 4 //\t} //\tif newCap \u0026lt;= 0 { //\tnewCap = expCap //\t} //\t} //} // 1.18 及以后 if expCap \u0026gt; doubleCap { newCap = expCap } else { if s.capacity \u0026lt; 256 { newCap = doubleCap } else { for 0 \u0026lt; newCap \u0026amp;\u0026amp; newCap \u0026lt; expCap { newCap += (newCap + 3*256) / 4 } if newCap \u0026lt;= 0 { newCap = expCap } } } newArrPtr := unsafe.Pointer(\u0026amp;make([]T, newCap)[0]) for i := 0; i \u0026lt; s.length; i++ { oldElemPtr := unsafe.Pointer(uintptr(s.array) + uintptr(i)*unsafe.Sizeof(*new(T))) newElemPtr := unsafe.Pointer(uintptr(newArrPtr) + uintptr(i)*unsafe.Sizeof(*new(T))) *(*T)(newElemPtr) = *(*T)(oldElemPtr) } s.array = newArrPtr s.capacity = newCap } func (s *Slice[T]) Get(idx int) T { if idx \u0026lt; 0 || idx \u0026gt;= s.length { panic(\u0026#34;index out of range\u0026#34;) } elemPtr := unsafe.Pointer(uintptr(s.array) + uintptr(idx)*unsafe.Sizeof(*new(T))) return *(*T)(elemPtr) } func (s *Slice[T]) Set(idx int, elem T) { if idx \u0026lt; 0 || idx \u0026gt;= s.length { panic(\u0026#34;index out of range\u0026#34;) } elemPtr := unsafe.Pointer(uintptr(s.array) + uintptr(idx)*unsafe.Sizeof(*new(T))) *(*T)(elemPtr) = elem } func (s *Slice[T]) Slice(leftBound, rightBound int) *Slice[T] { if leftBound \u0026lt; 0 || rightBound \u0026gt; s.length || leftBound \u0026gt; rightBound { panic(\u0026#34;invalid slice bounds\u0026#34;) } return \u0026amp;Slice[T]{ array: unsafe.Pointer(uintptr(s.array) + uintptr(leftBound)*unsafe.Sizeof(*new(T))), length: rightBound - leftBound, capacity: s.capacity - leftBound, } } func (s *Slice[T]) Del(idx int) { if idx \u0026lt; 0 || idx \u0026gt;= s.length { panic(\u0026#34;index out of range\u0026#34;) } newArrPtr := s.Slice(0, idx) newArrPtr.Append(s.Slice(idx+1, s.length).Array()...) s.array = newArrPtr.array s.length -= 1 s.capacity = newArrPtr.capacity } // 测试 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;some-go-demos/pkgs/my\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { mySlice := my.NewSlice[string](2) for i := 0; i \u0026lt; 10; i++ { mySlice.Append(strconv.Itoa(i)) } fmt.Println(mySlice.Get(5)) fmt.Println(mySlice.Slice(3, 6).Array()) mySlice.Del(5) fmt.Println(mySlice.Slice(3, 6).Array()) mySlice.Set(5, \u0026#34;hello\u0026#34;) fmt.Println(mySlice.Slice(3, 6).Array()) fmt.Println(\u0026#34;Len: \u0026#34;, mySlice.Len(), \u0026#34; Cap: \u0026#34;, mySlice.Cap()) } ","date":"2024-10-07T19:16:47+08:00","permalink":"https://finntew.github.io/p/golang-my-slice/","title":"Golang 笔记 - Slice 的底层原理 / 简单实现"}]